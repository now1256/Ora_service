# models/qwen_model.py (ë³„ë„ íŒŒì¼ë¡œ ë¶„ë¦¬)
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import logging

logger = logging.getLogger(__name__)

class QwenModel:
    """Qwen ëª¨ë¸ ì‹±ê¸€í†¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    _instance = None
    _model = None
    _tokenizer = None
    _is_initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(QwenModel, cls).__new__(cls)
        return cls._instance
    
    def initialize(self):
        """Qwen ëª¨ë¸ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
        if self._is_initialized:
            logger.info("Qwen ëª¨ë¸ì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
            
        if self._model is None:
            logger.info("ğŸš€ Qwen/Qwen2.5-7B-Instruct ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            try:
                self._model = AutoModelForCausalLM.from_pretrained(
                    "Qwen/Qwen2.5-7B-Instruct",
                    torch_dtype=torch.float16,
                    device_map="auto"
                )
                self._tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")
                self._is_initialized = True
                
                # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    logger.info(f"âœ… Qwen ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB ì‚¬ìš©)")
                else:
                    logger.info("âœ… Qwen ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (CPU ì‚¬ìš©)")
                    
            except Exception as e:
                logger.error(f"âŒ Qwen ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                self._is_initialized = False
                raise
    
    @property
    def model(self):
        """ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if not self._is_initialized:
            raise RuntimeError("Qwen ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        return self._model
    
    @property
    def tokenizer(self):
        """í† í¬ë‚˜ì´ì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if not self._is_initialized:
            raise RuntimeError("Qwen ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        return self._tokenizer
    
    @property
    def is_ready(self):
        """ëª¨ë¸ì´ ì‚¬ìš© ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self._is_initialized and self._model is not None and self._tokenizer is not None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
qwen_model = QwenModel()