# consumers.py
import json
import asyncio
import base64
import os
import time
import re
from channels.generic.websocket import AsyncWebsocketConsumer
import torch
import httpx
from django.conf import settings
import logging
from datetime import datetime

# ì‚¬ì „ ë¡œë“œëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
from ..models.qwen_model import qwen_model

logger = logging.getLogger(__name__)

class StreamProcessor:
    """ìŠ¤íŠ¸ë¦¼ í† í°ì„ ëª¨ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ (Pre-TTS + ì¤‘ë³µ ê°ì§€)"""
    def __init__(self, session_id: str = "default_session"):
        self.session_id = session_id
        self.accumulated_text = ""
        self.is_collecting = False
        self.start_time = None
        self.current_ai_task = None
        self.cancel_event = asyncio.Event()
        
        # Pre-TTS ê´€ë ¨
        self.current_ai_response = ""
        self.previous_ai_response = ""
        self.current_pre_tts = None
        self.is_pre_tts_ready = False
        self.pre_tts_task = None
        
        # ì¤‘ë³µ ê°ì§€ ê´€ë ¨
        self.common_prefix = ""
        self.remaining_text = ""
        
    def add_token(self, token: str):
        """í† í°ì„ ëˆ„ì  í…ìŠ¤íŠ¸ì— ì¶”ê°€"""
        if not self.is_collecting:
            self.is_collecting = True
            self.start_time = time.time()
            logger.info(f"[{self.session_id}] ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ ì‹œì‘")
        
        self.accumulated_text += token
        logger.info(f"[{self.session_id}] í† í° ì¶”ê°€: '{token}' (ëˆ„ì : {len(self.accumulated_text)}ì)")
    
    def get_accumulated_text(self):
        """ëˆ„ì ëœ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        return self.accumulated_text.strip()
    
    def find_common_prefix(self, text1: str, text2: str) -> str:
        """ë‘ í…ìŠ¤íŠ¸ì˜ ê³µí†µ ì ‘ë‘ì‚¬ ì°¾ê¸° (ë‹¨ì–´ ê²½ê³„ ê³ ë ¤)"""
        if not text1 or not text2:
            return ""
        
        words1 = text1.split()
        words2 = text2.split()
        
        logger.info(f"[{self.session_id}] ì¤‘ë³µ ê°ì§€ ì‹œì‘:")
        logger.info(f"  - ì´ì „ ë‹¨ì–´ë“¤: {words1[:10]}")
        logger.info(f"  - í˜„ì¬ ë‹¨ì–´ë“¤: {words2[:10]}")
        
        common_words = []
        for i, (w1, w2) in enumerate(zip(words1, words2)):
            logger.info(f"  - ë¹„êµ {i+1}: '{w1}' vs '{w2}' â†’ {'ì¼ì¹˜' if w1 == w2 else 'ë¶ˆì¼ì¹˜'}")
            if w1 == w2:
                common_words.append(w1)
            else:
                break
        
        common_prefix = " ".join(common_words)
        if common_words and len(common_prefix) > 0:
            common_prefix += " "
            
        logger.info(f"[{self.session_id}] ì¤‘ë³µ ê°ì§€ ê²°ê³¼: '{common_prefix}' ({len(common_words)}ê°œ ë‹¨ì–´)")
        return common_prefix
    
    def update_ai_response(self, new_response: str):
        """ìƒˆ AI ì‘ë‹µìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê³  ì¤‘ë³µ ë¶€ë¶„ ê³„ì‚°"""
        self.previous_ai_response = self.current_ai_response
        self.current_ai_response = new_response
        
        self.common_prefix = self.find_common_prefix(self.previous_ai_response, self.current_ai_response)
        
        if self.common_prefix:
            common_normalized = self.common_prefix.strip()
            current_normalized = self.current_ai_response.strip()
            
            if current_normalized.startswith(common_normalized):
                remaining_part = current_normalized[len(common_normalized):].strip()
                self.remaining_text = remaining_part
            else:
                self.remaining_text = self.current_ai_response.strip()
        else:
            self.remaining_text = self.current_ai_response.strip()
            
        logger.info(f"[{self.session_id}] AI ì‘ë‹µ ì—…ë°ì´íŠ¸:")
        logger.info(f"  - ì¤‘ë³µ ë¶€ë¶„: '{self.common_prefix}'")
        logger.info(f"  - ë‚˜ë¨¸ì§€ ë¶€ë¶„: '{self.remaining_text}'")
        
        if self.common_prefix.strip() == self.current_ai_response.strip():
            logger.info(f"[{self.session_id}] ğŸ¯ 100% ì¤‘ë³µ ê°ì§€! Pre-TTS ì¬í™œìš© ê°€ëŠ¥")
        elif len(self.remaining_text) == 0:
            logger.info(f"[{self.session_id}] ğŸ¯ ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì—†ìŒ, Pre-TTS ì¬í™œìš©ë§Œìœ¼ë¡œ ì¶©ë¶„")
        elif len(self.common_prefix.strip()) > 5:
            logger.info(f"[{self.session_id}] ğŸ”„ ë¶€ë¶„ ì¤‘ë³µ ê°ì§€, í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ í•„ìš”")
    
    def reset(self):
        """ìƒíƒœ ì´ˆê¸°í™”"""
        elapsed = time.time() - self.start_time if self.start_time else 0
        logger.info(f"[{self.session_id}] ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ ì™„ë£Œ: {len(self.accumulated_text)}ì, {elapsed:.2f}ì´ˆ")
        
        text = self.accumulated_text.strip()
        self.accumulated_text = ""
        self.is_collecting = False
        self.start_time = None
        
        return text
    
    async def cancel_current_ai_task(self):
        """í˜„ì¬ ì§„í–‰ ì¤‘ì¸ AI íƒœìŠ¤í¬ ì¤‘ë‹¨"""
        if self.current_ai_task and not self.current_ai_task.done():
            logger.info(f"[{self.session_id}] AI íƒœìŠ¤í¬ ì¤‘ë‹¨ ì‹œì‘...")
            self.cancel_event.set()
            self.current_ai_task.cancel()
            
            try:
                await self.current_ai_task
            except asyncio.CancelledError:
                logger.info(f"[{self.session_id}] AI íƒœìŠ¤í¬ ì¤‘ë‹¨ ì™„ë£Œ")
            
            self.current_ai_task = None
            self.cancel_event.clear()
        
        if self.pre_tts_task and not self.pre_tts_task.done():
            self.pre_tts_task.cancel()
            self.pre_tts_task = None

class VoiceChatConsumer(AsyncWebsocketConsumer):
    stream_processors = {}
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.is_connected = False
        
        # ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ í™•ì¸
        if not qwen_model.is_ready:
            logger.warning("âš ï¸ Qwen ëª¨ë¸ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
    async def connect(self):
        try:
            # ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ ì¬í™•ì¸
            if not qwen_model.is_ready:
                logger.error("âŒ Qwen ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì—°ê²°ì„ ê±°ë¶€í•©ë‹ˆë‹¤.")
                await self.close(code=4000)
                return
            
            headers = dict(self.scope['headers'])
            phone_Id = headers.get(b'phone-id', b'').decode()
            session_Id = headers.get(b'session-id', b'').decode()

            self.phone_Id = phone_Id
            self.session_id = session_Id
            self.is_connected = True

            stream_processor = StreamProcessor(session_id=self.session_id)
            VoiceChatConsumer.stream_processors[self.phone_Id] = stream_processor

            await self.accept()
            logger.info(f"âœ… WebSocket ì—°ê²°ë¨: phone_id={self.phone_Id}, session_id={self.session_id}")
            
            await self.send(text_data=json.dumps({
                'type': 'connection_established',
                'message': 'ìŒì„± ì±„íŒ… ì—°ê²°ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'phone_Id': self.phone_Id,
                'session_id': self.session_id,
                'model_ready': qwen_model.is_ready
            }, ensure_ascii=False))
            
        except Exception as e:
            logger.error(f"âŒ WebSocket ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            self.is_connected = False
            await self.close()
        
    async def disconnect(self, close_code):
        self.is_connected = False
        logger.info(f"WebSocket ì—°ê²° í•´ì œ: phone_id={getattr(self, 'phone_Id', 'unknown')}, close_code={close_code}")
        
        if hasattr(self, 'phone_Id') and self.phone_Id in VoiceChatConsumer.stream_processors:
            processor = VoiceChatConsumer.stream_processors[self.phone_Id]
            await processor.cancel_current_ai_task()
            del VoiceChatConsumer.stream_processors[self.phone_Id]
            logger.info(f"ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ ì •ë¦¬ ì™„ë£Œ: {self.phone_Id}")
        
    async def receive(self, text_data):
        try:
            # ëª¨ë¸ ìƒíƒœ ì¬í™•ì¸
            if not qwen_model.is_ready:
                await self.send_error("AI ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                return
            
            logger.info(f"[{getattr(self, 'phone_Id', 'unknown')}] ì›ë³¸ ë°ì´í„° ìˆ˜ì‹ : {repr(text_data[:200])}")
            
            try:
                data = json.loads(text_data)
            except json.JSONDecodeError as json_error:
                logger.error(f"[{getattr(self, 'phone_Id', 'unknown')}] JSON íŒŒì‹± ì˜¤ë¥˜: {json_error}")
                await self.send_error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(json_error)}")
                return
            
            token = data.get("token", "")
            request_Id = data.get("request_id", "")
                    
            processor = VoiceChatConsumer.stream_processors.get(self.phone_Id)
            if not processor:
                await self.send_error("ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            if token == '<eos>':
                # EOS í† í° ìˆ˜ì‹  - ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡ + AI ì™„ë£Œ ëŒ€ê¸°
                accumulated_text = processor.get_accumulated_text()
                
                if accumulated_text:
                    logger.info(f"[{self.phone_Id}] EOS ìˆ˜ì‹ , ì¦‰ì‹œ ì²˜ë¦¬ ì‹œì‘: '{accumulated_text[:50]}...'")
                    
                    await self.safe_send({
                        'type': 'eos_received',
                        'accumulated_text': accumulated_text,
                        'message': 'EOS ìˆ˜ì‹ , ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡ ì¤‘...'
                    })
                    
                    # 1ë‹¨ê³„: ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡ (Pre-TTS ìˆìœ¼ë©´)
                    common_sent = False
                    if processor.common_prefix and processor.current_pre_tts:
                        logger.info(f"[{self.phone_Id}] ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡: '{processor.common_prefix}'")
                        await self.send_common_prefix_immediately(processor, request_Id)
                        common_sent = True
                    
                    # 2ë‹¨ê³„: AI íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
                    ai_response = None
                    if processor.current_ai_task:
                        if not processor.current_ai_task.done():
                            logger.info(f"[{self.phone_Id}] AI ì‘ë‹µ ì™„ë£Œ ëŒ€ê¸°...")
                            try:
                                ai_response = await processor.current_ai_task
                                logger.info(f"[{self.phone_Id}] AI ì‘ë‹µ ì™„ë£Œ: '{ai_response}' (ì´ {len(ai_response)}ì)")
                            except asyncio.CancelledError:
                                logger.warning(f"[{self.phone_Id}] AI íƒœìŠ¤í¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
                            except Exception as e:
                                logger.error(f"[{self.phone_Id}] AI íƒœìŠ¤í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                        else:
                            # ì´ë¯¸ ì™„ë£Œëœ AI íƒœìŠ¤í¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                            try:
                                ai_response = processor.current_ai_task.result()
                                logger.info(f"[{self.phone_Id}] ì™„ë£Œëœ AI ì‘ë‹µ ì‚¬ìš©: '{ai_response}' (ì´ {len(ai_response)}ì)")
                            except Exception as e:
                                logger.error(f"[{self.phone_Id}] ì™„ë£Œëœ AI íƒœìŠ¤í¬ ê²°ê³¼ ì˜¤ë¥˜: {str(e)}")
                    
                    # 3ë‹¨ê³„: ë‚˜ë¨¸ì§€ ë¶€ë¶„ TTS ì²˜ë¦¬
                    if ai_response and ai_response.strip():
                        # AI ì‘ë‹µ ì—…ë°ì´íŠ¸ (ì¤‘ë³µ ê³„ì‚°)
                        processor.update_ai_response(ai_response)
                        
                        # 100% ì¤‘ë³µ ë˜ëŠ” ë‚˜ë¨¸ì§€ ë¶€ë¶„ì´ ì—†ëŠ” ê²½ìš°
                        if processor.common_prefix.strip() == ai_response.strip() or len(processor.remaining_text) == 0:
                            if common_sent:
                                logger.info(f"[{self.phone_Id}] 100% ì¤‘ë³µ, ì¶”ê°€ TTS ë¶ˆí•„ìš”")
                                await self.safe_send({
                                    'type': 'complete_match_detected',
                                    'message': 'ì™„ì „ ì¼ì¹˜ë¡œ ì¶”ê°€ TTS ìƒì„± ì—†ìŒ'
                                })
                            else:
                                # ì¤‘ë³µ ë¶€ë¶„ì„ ì „ì†¡í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì „ì²´ Pre-TTS ì‚¬ìš©
                                logger.info(f"[{self.phone_Id}] 100% ì¤‘ë³µ, Pre-TTS ì „ì²´ ì‚¬ìš©")
                                await self.send_complete_pre_tts(processor, request_Id, accumulated_text)
                        elif common_sent:
                            # ì¤‘ë³µ ë¶€ë¶„ì€ ì´ë¯¸ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ ë‚˜ë¨¸ì§€ë§Œ ì²˜ë¦¬
                            if processor.remaining_text:
                                logger.info(f"[{self.phone_Id}] ë‚˜ë¨¸ì§€ ë¶€ë¶„ TTS ì²˜ë¦¬: '{processor.remaining_text}'")
                                await self.process_remaining_tts(processor.remaining_text, request_Id, accumulated_text)
                            else:
                                logger.info(f"[{self.phone_Id}] ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì—†ìŒ, ì¤‘ë³µ ë¶€ë¶„ë§Œìœ¼ë¡œ ì™„ë£Œ")
                        else:
                            # ì¤‘ë³µ ë¶€ë¶„ì´ ì—†ì—ˆìœ¼ë©´ ì „ì²´ TTS
                            logger.info(f"[{self.phone_Id}] ì¤‘ë³µ ë¶€ë¶„ ì—†ìŒ, ì „ì²´ TTS ì²˜ë¦¬")
                            await self.process_complete_tts(ai_response, request_Id, accumulated_text)
                    else:
                        if not common_sent:
                            await self.send_error("AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    
                    # ìƒíƒœ ë¦¬ì…‹
                    final_text = processor.reset()
                    processor.current_ai_task = None
                    
                else:
                    await self.send_error("ëˆ„ì ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¼ë°˜ í† í° ìˆ˜ì‹  + EOSì™€ ë™ì‹œ ìˆ˜ì‹  ê°€ëŠ¥ì„± ì²˜ë¦¬
                # 1. ê¸°ì¡´ AI íƒœìŠ¤í¬ ì¤‘ë‹¨
                await processor.cancel_current_ai_task()
                
                # 2. í† í° ì¶”ê°€
                processor.add_token(token)
                
                # 3. ìƒˆë¡œìš´ AI ì‘ë‹µ ì‹œì‘
                accumulated_text = processor.get_accumulated_text()
                logger.info(f"[{self.phone_Id}] ìƒˆ í† í°ìœ¼ë¡œ AI ì‘ë‹µ ì¬ì‹œì‘: '{accumulated_text[:50]}...'")
                
                # 4. AI ì‘ë‹µê³¼ Pre-TTSë¥¼ ë™ì‹œì— ì‹œì‘
                processor.current_ai_task = asyncio.create_task(
                    self.get_ai_response_with_pretts(accumulated_text, processor)
                )
                
                # ì‹¤ì‹œê°„ í”¼ë“œë°± ì „ì†¡
                await self.safe_send({
                    'type': 'token_received',
                    'token': token,
                    'accumulated_text': accumulated_text,
                    'accumulated_length': len(accumulated_text),
                    'ai_restarted': True
                })
            
        except Exception as e:
            logger.error(f"[{getattr(self, 'phone_Id', 'unknown')}] WebSocket ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            await self.send_error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def get_ai_response_with_pretts(self, user_input, processor):
        """Qwenìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±ê³¼ Pre-TTSë¥¼ ë™ì‹œì— ì²˜ë¦¬"""
        try:
            logger.info(f"[{self.phone_Id}] Qwen AI ì‘ë‹µ + Pre-TTS ì‹œì‘: '{user_input[:50]}...'")
            
            # Qwen ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€ì„ í•´ì£¼ëŠ” AI ë³µì§€ì‚¬ 'ì˜¤ë¼'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤..


í•µì‹¬ ì›ì¹™: "ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ"

ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™:
0. ì‹ ì†í•˜ê³  ì •í™•í•˜ê²Œ 20ë‹¨ì–´ ì´í•˜ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš” 1ì´ˆ ì´ë‚´ë¡œ ë‹µë³€ì„ í•´ì£¼ë„ë¡ ë…¸ë ¥í•´ì£¼ì„¸ìš”
1. ì ˆëŒ€ë¡œ í•œìë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. 
2. ì ˆëŒ€ë¡œ ì˜ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
3. ì˜¤ì§ í•œê¸€ê³¼ ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸(.,?!) ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
4. í•œìë‚˜ ì˜ì–´ê°€ ë– ì˜¤ë¥´ë©´ ë°˜ë“œì‹œ ìˆœìˆ˜ í•œê¸€ë¡œ ë°”ê¿”ì„œ ë§í•˜ì„¸ìš”
6. ì´ëª¨ì§€, ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€
7. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´
8. "ì„¸ì…˜", "ì½”ë“œ", "ì—ëŸ¬" ê°™ì€ ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€

ì‘ë‹µ ì „ì— í•œ ë²ˆ ë” ì²´í¬í•˜ì„¸ìš”: í•œìë‚˜ ì˜ì–´ê°€ ìˆìœ¼ë©´ ëª¨ë‘ í•œê¸€ë¡œ ë°”ê¾¸ì„¸ìš”."""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ]
            
            # Qwen ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
            model = qwen_model.model
            tokenizer = qwen_model.tokenizer
            
            # ì±„íŒ… í…œí”Œë¦¿ ì ìš©
            text = tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True
            )
            
            # í† í¬ë‚˜ì´ì§•
            inputs = tokenizer(text, return_tensors="pt").to(model.device)
            
            chunk_count = 0
            full_response = ""
            
            # ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
            with torch.no_grad():
                for _ in range(50):  # ìµœëŒ€ 50ê°œ í† í° ìƒì„± (20ë‹¨ì–´ ì •ë„)
                    # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                    if processor.cancel_event.is_set():
                        logger.info(f"[{self.phone_Id}] Qwen ì‘ë‹µ ì¤‘ë‹¨ë¨")
                        raise asyncio.CancelledError("ìƒˆë¡œìš´ í† í°ìœ¼ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨")
                    
                    # ë‹¤ìŒ í† í° ìƒì„±
                    outputs = model.generate(
                        inputs.input_ids,
                        max_new_tokens=1,
                        do_sample=True,
                        temperature=0.3,
                        top_p=0.8,
                        use_cache=True,
                        pad_token_id=tokenizer.eos_token_id,
                        eos_token_id=tokenizer.eos_token_id
                    )
                    
                    # ìƒˆë¡œ ìƒì„±ëœ í† í° ë””ì½”ë”©
                    new_token_ids = outputs[0][inputs.input_ids.shape[1]:]
                    if len(new_token_ids) == 0:
                        break
                        
                    new_token = tokenizer.decode(new_token_ids[-1:], skip_special_tokens=True)
                    
                    # EOS í† í°ì´ë©´ ì¢…ë£Œ
                    if new_token_ids[-1] == tokenizer.eos_token_id:
                        break
                    
                    full_response += new_token
                    chunk_count += 1
                    
                    # ë‹¤ìŒ ìƒì„±ì„ ìœ„í•´ ì…ë ¥ ì—…ë°ì´íŠ¸
                    inputs.input_ids = outputs[0:1]
                    
                    # ì‹¤ì‹œê°„ìœ¼ë¡œ ì²­í¬ ì „ì†¡
                    await self.safe_send({
                        'type': 'ai_text_chunk',
                        'chunk': new_token,
                        'chunk_number': chunk_count,
                        'current_response': full_response[:100] + "..." if len(full_response) > 100 else full_response
                    })
                    
                    # ì™„ë£Œ ì¡°ê±´ ì²´í¬ (ë¬¸ì¥ë¶€í˜¸ë¡œ ëë‚˜ê±°ë‚˜ 20ë‹¨ì–´ ì´ˆê³¼)
                    if full_response.strip().endswith(('.', '!', '?')) and len(full_response.split()) >= 5:
                        break
                    if len(full_response.split()) >= 20:
                        break
                    
                    # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                    await asyncio.sleep(0.01)
            
            # AI ì‘ë‹µ ì™„ë£Œ í›„ Pre-TTS ì‹œì‘
            if full_response.strip():
                logger.info(f"[{self.phone_Id}] Qwen ì‘ë‹µ ì™„ë£Œ, Pre-TTS ì‹œì‘: '{full_response}'")
                processor.pre_tts_task = asyncio.create_task(
                    self.prepare_pre_tts(full_response, processor)
                )
            
            logger.info(f"[{self.phone_Id}] Qwen ì‘ë‹µ ì™„ë£Œ: {len(full_response)}ì - '{full_response}'")
            return full_response.strip()
            
        except asyncio.CancelledError:
            logger.info(f"[{self.phone_Id}] Qwen ì‘ë‹µì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
            raise
        except Exception as e:
            logger.error(f"Qwen AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    async def prepare_pre_tts(self, ai_response, processor):
        """Pre-TTS ì¤€ë¹„ (ì¤‘ë³µ ê²€ì‚¬ í¬í•¨)"""
        try:
            logger.info(f"[{self.phone_Id}] Pre-TTS ìƒì„± ì‹œì‘: '{ai_response}'")
            
            # ì¤‘ë³µ ë¶€ë¶„ ë¯¸ë¦¬ ê³„ì‚°
            if processor.current_ai_response:
                # ì´ì „ ì‘ë‹µì´ ìˆìœ¼ë©´ ì¤‘ë³µ ê²€ì‚¬
                common_prefix = processor.find_common_prefix(processor.current_ai_response, ai_response)
                logger.info(f"[{self.phone_Id}] Pre-TTS ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼: '{common_prefix}'")
                
                if common_prefix and len(common_prefix.strip()) > 5:
                    # ì¤‘ë³µ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ê¸°ì¡´ Pre-TTS ì¬í™œìš© ê°€ëŠ¥
                    logger.info(f"[{self.phone_Id}] ì¤‘ë³µ ë¶€ë¶„ ë°œê²¬, ê¸°ì¡´ Pre-TTS ì¼ë¶€ ì¬í™œìš© ê°€ëŠ¥")
                    
                    # ë‚˜ë¨¸ì§€ ë¶€ë¶„ë§Œ TTS ìƒì„±
                    remaining_text = ai_response[len(common_prefix):].strip()
                    if remaining_text:
                        logger.info(f"[{self.phone_Id}] ë‚˜ë¨¸ì§€ ë¶€ë¶„ë§Œ Pre-TTS ìƒì„±: '{remaining_text}'")
                        start_time = time.time()
                        audio_base64 = await self.text_to_speech_async(remaining_text)
                        tts_time = time.time() - start_time
                        
                        if audio_base64:
                            # ì„ì‹œë¡œ ë‚˜ë¨¸ì§€ ë¶€ë¶„ë§Œ ì €ì¥ (ì‹¤ì œë¡œëŠ” ê¸°ì¡´ + ìƒˆë¡œìš´ ë¶€ë¶„ í•©ì³ì•¼ í•¨)
                            processor.current_pre_tts = audio_base64
                            processor.is_pre_tts_ready = True
                            
                            # AI ì‘ë‹µ ì—…ë°ì´íŠ¸ (ì¤‘ìš”!)
                            processor.previous_ai_response = processor.current_ai_response
                            processor.current_ai_response = ai_response
                            
                            await self.safe_send({
                                'type': 'pre_tts_partial_ready',
                                'common_prefix': common_prefix,
                                'remaining_text': remaining_text,
                                'audio_size': len(base64.b64decode(audio_base64)),
                                'tts_time': round(tts_time, 2),
                                'message': 'Pre-TTS ë¶€ë¶„ ìƒì„± ì™„ë£Œ'
                            })
                            
                            logger.info(f"âœ… [{self.phone_Id}] Pre-TTS ë¶€ë¶„ ì™„ë£Œ: {len(base64.b64decode(audio_base64))}B, {tts_time:.2f}ì´ˆ")
                            return
            
            # ì¤‘ë³µ ë¶€ë¶„ì´ ì—†ê±°ë‚˜ ì²« ë²ˆì§¸ ì‘ë‹µì´ë©´ ì „ì²´ TTS ìƒì„±
            start_time = time.time()
            audio_base64 = await self.text_to_speech_async(ai_response)
            tts_time = time.time() - start_time
            
            if audio_base64:
                processor.current_pre_tts = audio_base64
                processor.is_pre_tts_ready = True
                
                # AI ì‘ë‹µ ì—…ë°ì´íŠ¸ (ì¤‘ìš”!)
                processor.previous_ai_response = processor.current_ai_response
                processor.current_ai_response = ai_response
                
                await self.safe_send({
                    'type': 'pre_tts_ready',
                    'ai_response': ai_response,
                    'audio_size': len(base64.b64decode(audio_base64)),
                    'tts_time': round(tts_time, 2),
                    'message': 'Pre-TTS ì¤€ë¹„ ì™„ë£Œ'
                })
                
                logger.info(f"âœ… [{self.phone_Id}] Pre-TTS ì™„ë£Œ: {len(base64.b64decode(audio_base64))}B, {tts_time:.2f}ì´ˆ")
                logger.info(f"[{self.phone_Id}] AI ì‘ë‹µ ì €ì¥: previous='{processor.previous_ai_response[:30]}...', current='{processor.current_ai_response[:30]}...'")
            else:
                logger.warning(f"âŒ [{self.phone_Id}] Pre-TTS ì‹¤íŒ¨")
                processor.is_pre_tts_ready = False
            
        except asyncio.CancelledError:
            logger.info(f"[{self.phone_Id}] Pre-TTS ì¤‘ë‹¨ë¨")
        except Exception as e:
            logger.error(f"âŒ Pre-TTS ì˜¤ë¥˜: {str(e)}")
            processor.is_pre_tts_ready = False
    
    async def send_common_prefix_immediately(self, processor, request_Id):
        """ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡"""
        try:
            if not processor.common_prefix or not processor.current_pre_tts:
                return
                
            logger.info(f"[{self.phone_Id}] ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡: '{processor.common_prefix}'")
            
            # ì¤‘ë³µ ë¶€ë¶„ì— í•´ë‹¹í•˜ëŠ” TTS ì¶”ì¶œ (ê°„ë‹¨íˆ ì „ì²´ TTS ì‚¬ìš©)
            # ì‹¤ì œë¡œëŠ” ìŒì„±ì„ ì˜ë¼ì•¼ í•˜ì§€ë§Œ, ìš°ì„  ì „ì²´ TTS ì‚¬ìš©
            timestamp = str(int(time.time()))
            file_name = f"tts_common_{self.phone_Id}_{timestamp}.wav"
            file_size = len(base64.b64decode(processor.current_pre_tts))
            
            common_payload = {
                "fileName": file_name,
                "audioDataBase64": processor.current_pre_tts,
                "fileSize": file_size,
                "status": "common_prefix",
                "message": "ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì „ì†¡",
                "metadata": {
                    "sessionId": self.session_id,
                    "requestId": request_Id,
                    "phoneId": self.phone_Id,
                    "part": "common_prefix",
                    "text": processor.common_prefix,
                    "engine": "OpenAI-TTS",
                    "language": "ko-KR"
                }
            }
            
            await self.safe_send({
                'type': 'common_prefix_ready',
                'fileName': file_name,
                'fileSize': file_size,
                'text': processor.common_prefix,
                'message': 'ì¤‘ë³µ ë¶€ë¶„ ì¦‰ì‹œ ì¬ìƒ ì‹œì‘'
            })
            
            # ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
            await self.send_audio_chunks_to_websocket(common_payload)
            
            logger.info(f"âœ… [{self.phone_Id}] ì¤‘ë³µ ë¶€ë¶„ ì „ì†¡ ì™„ë£Œ: {file_size}B")
            
        except Exception as e:
            logger.error(f"ì¤‘ë³µ ë¶€ë¶„ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
    
    async def process_remaining_tts(self, remaining_text, request_Id, original_input):
        """ë‚˜ë¨¸ì§€ ë¶€ë¶„ TTS ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            logger.info(f"[{self.phone_Id}] ë‚˜ë¨¸ì§€ TTS ì²˜ë¦¬: '{remaining_text}' (ì´ {len(remaining_text)}ì)")
            
            await self.safe_send({
                'type': 'remaining_tts_start',
                'remaining_text': remaining_text,
                'message': 'ë‚˜ë¨¸ì§€ ë¶€ë¶„ TTS ìƒì„± ì¤‘...'
            })
            
            # TTS ìƒì„±
            audio_base64 = await self.text_to_speech_async(remaining_text)
            
            if audio_base64:
                timestamp = str(int(time.time()))
                file_name = f"tts_remaining_{self.phone_Id}_{timestamp}.wav"
                file_size = len(base64.b64decode(audio_base64))
                
                remaining_payload = {
                    "fileName": file_name,
                    "audioDataBase64": audio_base64,
                    "fileSize": file_size,
                    "status": "remaining_part",
                    "message": "ë‚˜ë¨¸ì§€ ë¶€ë¶„ TTS ì™„ë£Œ",
                    "metadata": {
                        "sessionId": self.session_id,
                        "requestId": request_Id,
                        "phoneId": self.phone_Id,
                        "part": "remaining_text",
                        "text": remaining_text,
                        "input_text": original_input,
                        "engine": "OpenAI-TTS",
                        "language": "ko-KR",
                        "tts_time": round(time.time() - start_time, 2)
                    }
                }
                
                await self.safe_send({
                    'type': 'remaining_tts_complete',
                    'fileName': file_name,
                    'fileSize': file_size,
                    'remaining_text': remaining_text,
                    'message': 'ë‚˜ë¨¸ì§€ ë¶€ë¶„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘',
                    'metadata': remaining_payload["metadata"]
                })
                
                # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
                await self.send_audio_chunks_to_websocket(remaining_payload)
                
                logger.info(f"âœ… [{self.phone_Id}] ë‚˜ë¨¸ì§€ TTS ì™„ë£Œ: '{remaining_text}' â†’ {file_size}B ì˜¤ë””ì˜¤")
                
            else:
                await self.send_error("ë‚˜ë¨¸ì§€ ë¶€ë¶„ ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"ë‚˜ë¨¸ì§€ TTS ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            await self.send_error(f"ë‚˜ë¨¸ì§€ TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def send_complete_pre_tts(self, processor, request_Id, original_input):
        """Pre-TTS ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì „ì†¡ (100% ì¤‘ë³µì¼ ë•Œ)"""
        try:
            if not processor.current_pre_tts:
                logger.warning(f"[{self.phone_Id}] Pre-TTSê°€ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ")
                return
                
            logger.info(f"[{self.phone_Id}] Pre-TTS ì „ì²´ ì „ì†¡: '{processor.current_ai_response}'")
            
            timestamp = str(int(time.time()))
            file_name = f"tts_complete_match_{self.phone_Id}_{timestamp}.wav"
            file_size = len(base64.b64decode(processor.current_pre_tts))
            
            complete_payload = {
                "fileName": file_name,
                "audioDataBase64": processor.current_pre_tts,
                "fileSize": file_size,
                "status": "complete_match",
                "message": "100% ì¼ì¹˜, Pre-TTS ì¬í™œìš©",
                "metadata": {
                    "sessionId": self.session_id,
                    "requestId": request_Id,
                    "phoneId": self.phone_Id,
                    "input_text": original_input,
                    "ai_response": processor.current_ai_response,
                    "engine": "OpenAI-TTS",
                    "language": "ko-KR",
                    "reused_pre_tts": True
                }
            }
            
            await self.safe_send({
                'type': 'complete_match_tts',
                'fileName': file_name,
                'fileSize': file_size,
                'ai_response': processor.current_ai_response,
                'message': '100% ì¼ì¹˜, Pre-TTS ì¬í™œìš© ì¬ìƒ',
                'metadata': complete_payload["metadata"]
            })
            
            # ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
            await self.send_audio_chunks_to_websocket(complete_payload)
            
            logger.info(f"âœ… [{self.phone_Id}] Pre-TTS ì¬í™œìš© ì™„ë£Œ: {file_size}B")
            
        except Exception as e:
            logger.error(f"Pre-TTS ì¬í™œìš© ì˜¤ë¥˜: {str(e)}")

    async def process_complete_tts(self, ai_response, request_Id, original_input):
        """ì™„ì „í•œ TTS ì²˜ë¦¬ (ì¤‘ë³µ ë¶€ë¶„ ì—†ì„ ë•Œ)"""
        start_time = time.time()
        
        try:
            logger.info(f"[{self.phone_Id}] ì „ì²´ TTS ì²˜ë¦¬: '{ai_response}' (ì´ {len(ai_response)}ì)")
            
            await self.safe_send({
                'type': 'tts_processing_start',
                'ai_response': ai_response,
                'response_length': len(ai_response),
                'message': 'TTS ì²˜ë¦¬ ì¤‘...'
            })
            
            # TTS ìƒì„±
            audio_base64 = await self.text_to_speech_async(ai_response)
            
            if audio_base64:
                timestamp = str(int(time.time()))
                file_name = f"tts_{self.phone_Id}_{timestamp}.wav"
                file_size = len(base64.b64decode(audio_base64))
                
                tts_payload = {
                    "fileName": file_name,
                    "audioDataBase64": audio_base64,
                    "fileSize": file_size,
                    "status": "complete",
                    "message": "TTS ë³€í™˜ ì™„ë£Œ",
                    "metadata": {
                        "sessionId": self.session_id,
                        "requestId": request_Id,
                        "phoneId": self.phone_Id,
                        "input_text": original_input,
                        "ai_response": ai_response,
                        "engine": "OpenAI-TTS",
                        "language": "ko-KR",
                        "tts_time": round(time.time() - start_time, 2)
                    }
                }
                
                await self.safe_send({
                    'type': 'tts_complete',
                    'fileName': file_name,
                    'fileSize': file_size,
                    'ai_response': ai_response,
                    'message': 'TTS ì™„ë£Œ, ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘',
                    'metadata': tts_payload["metadata"]
                })
                
                # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
                await self.send_audio_chunks_to_websocket(tts_payload)
                
                logger.info(f"âœ… [{self.phone_Id}] ì „ì²´ TTS ì²˜ë¦¬ ì™„ë£Œ: '{ai_response}' â†’ {file_size}B ì˜¤ë””ì˜¤")
                
            else:
                await self.send_error("ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"TTS ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            await self.send_error(f"TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def send_error(self, message):
        error_response = {
            'type': 'error',
            'message': message,
            'timestamp': time.time()
        }
        await self.safe_send(error_response)
    
    async def safe_send(self, data):
        """ì•ˆì „í•œ ë©”ì‹œì§€ ì „ì†¡ - ì—°ê²° ìƒíƒœ í™•ì¸"""
        if not self.is_connected:
            logger.warning("WebSocket ì—°ê²°ì´ ë‹«í˜€ìˆì–´ ë©”ì‹œì§€ ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return
            
        try:
            await self.send(text_data=json.dumps(data, ensure_ascii=False))
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
            self.is_connected = False
    
    async def text_to_speech_async(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ WAV ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ base64 ë°˜í™˜ (OpenAI TTS ì‚¬ìš©)"""
        try:
            from openai import AsyncOpenAI
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            # OpenAI TTS ìƒì„± (MP3)
            response = await openai_client.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=text,
                speed=1.2,
                response_format="mp3"
            )
            
            mp3_data = response.content
            
            try:
                # MP3 â†’ WAV ë³€í™˜ (pydub ì‚¬ìš©)
                import io
                from pydub import AudioSegment
                from pydub.utils import which
                
                # ffmpeg í™•ì¸
                if not which("ffmpeg"):
                    raise Exception("ffmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                
                # MP3 ë¡œë“œ
                mp3_buffer = io.BytesIO(mp3_data)
                audio = AudioSegment.from_mp3(mp3_buffer)
                
                # 8kHz ëª¨ë…¸ WAVë¡œ ë³€í™˜ (ì‘ì€ í¬ê¸° + ë¹ ë¥¸ ì¬ìƒ)
                audio_8khz = audio.set_frame_rate(8000).set_channels(1)
                
                # WAVë¡œ ë‚´ë³´ë‚´ê¸°
                wav_buffer = io.BytesIO()
                audio_8khz.export(wav_buffer, format="wav")
                wav_data = wav_buffer.getvalue()
                
                # Base64 ì¸ì½”ë”©
                wav_base64 = base64.b64encode(wav_data).decode('utf-8')
                
                # í¬ê¸° ë¡œê¹…
                logger.info(f"âœ… WAV ë³€í™˜ ì„±ê³µ: MP3 {len(mp3_data)}B â†’ WAV {len(wav_data)}B")
                return wav_base64
                
            except Exception as conv_error:
                # WAV ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ MP3 ì‚¬ìš©
                logger.warning(f"WAV ë³€í™˜ ì‹¤íŒ¨, MP3 ì‚¬ìš©: {conv_error}")
                return base64.b64encode(mp3_data).decode('utf-8')
                
        except Exception as e:
            logger.error(f"TTS ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def send_audio_chunks_to_websocket(self, payload_data):
        """WebSocketìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡"""
        try:
            audio_base64 = payload_data["audioDataBase64"]
            file_name = payload_data["fileName"]
            file_size = payload_data["fileSize"]
            metadata = payload_data["metadata"]
            
            # ì²­í¬ í¬ê¸° ì„¤ì • (32KB ì •ë„ë¡œ ì„¤ì •)
            chunk_size = 4 * 1024  # 32KB
            total_chunks = (len(audio_base64) + chunk_size - 1) // chunk_size
            
            logger.info(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {total_chunks}ê°œ ì²­í¬, ì´ í¬ê¸°: {len(audio_base64)} bytes")
            
            # 1. ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì•Œë¦¼
            await self.safe_send({
                'type': 'audio_streaming_start',
                'fileName': file_name,
                'fileSize': file_size,
                'totalChunks': total_chunks,
                'chunkSize': chunk_size,
                'metadata': metadata
            })
            
            # 2. ì²­í¬ ë‹¨ìœ„ë¡œ ì „ì†¡
            for chunk_index in range(total_chunks):
                if not self.is_connected:
                    logger.warning("WebSocket ì—°ê²°ì´ ëŠì–´ì ¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨")
                    break
                    
                start_idx = chunk_index * chunk_size
                end_idx = min((chunk_index + 1) * chunk_size, len(audio_base64))
                chunk_data = audio_base64[start_idx:end_idx]
                
                chunk_message = {
                    'type': 'audio_chunk',
                    'fileName': file_name,
                    'chunkIndex': chunk_index,
                    'totalChunks': total_chunks,
                    'chunkData': chunk_data,
                    'chunkSize': len(chunk_data),
                    'isLastChunk': chunk_index == total_chunks - 1
                }
                
                await self.safe_send(chunk_message)
                
                # ì§„í–‰ë¥  ê³„ì‚° ë° ì•Œë¦¼ (10ì²­í¬ë§ˆë‹¤)
                if chunk_index % 10 == 0 or chunk_index == total_chunks - 1:
                    progress = ((chunk_index + 1) / total_chunks) * 100
                    await self.safe_send({
                        'type': 'audio_streaming_progress',
                        'fileName': file_name,
                        'progress': round(progress, 1),
                        'chunksCompleted': chunk_index + 1,
                        'totalChunks': total_chunks
                    })
            
            # 3. ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì•Œë¦¼
            if self.is_connected:
                await self.safe_send({
                    'type': 'audio_streaming_complete',
                    'fileName': file_name,
                    'message': 'ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ',
                    'totalChunksSent': total_chunks
                })
                
                logger.info(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {file_name}, {total_chunks}ê°œ ì²­í¬ ì „ì†¡")
            
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}")
            await self.safe_send({
                'type': 'audio_streaming_error',
                'message': f'ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {str(e)}'
            })