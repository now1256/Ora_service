# ai/consumers.py
import json
import asyncio
import os
import sys
import time
import threading
from typing import Dict, Any, Optional
from datetime import datetime

from django.conf import settings
from channels.generic.websocket import AsyncWebsocketConsumer
from dotenv import load_dotenv
import logging
import torch
from ..utils.prompts import prompt
from ..models.qwen_model import qwen_model

logger = logging.getLogger(__name__)


# API KEY ì •ë³´ë¡œë“œ
load_dotenv()


class QwenStreamProcessor:
    def __init__(self, session_id: str = "default_session"):
        self.session_id = session_id
        self.current_question = ""
        self.is_processing = False
        self.current_task: Optional[asyncio.Task] = None
        self.cancel_event = threading.Event()
        self.is_eos_received = False

        # ë§ˆì§€ë§‰ ì™„ë£Œëœ ì‘ë‹µ ì €ì¥
        self.last_completed_response = ""
        self.last_completed_question = ""

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
        self.conversation_history = []
        
        # ëª¨ë¸ ì •ë³´
        self.model_name = "Qwen/Qwen2.5-7B-Instruct"
        
   

    async def process_stream_token(self, token: str) -> Dict[str, Any]:
        """ìŠ¤íŠ¸ë¦¼ í† í°ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë©”ì„œë“œ"""

        logger.info(f"ğŸ¯ [{self.session_id}] í† í° ìˆ˜ì‹ : '{token}'")

        if token == '<eos>':
            logger.info(f"ğŸ [{self.session_id}] EOS ê°ì§€ - í˜„ì¬ ì§„í–‰ì¤‘ì¸ ë‹µë³€ì„ ëê¹Œì§€ ì™„ë£Œí•©ë‹ˆë‹¤.")
            self.is_eos_received = True

            if self.current_task and not self.current_task.done():
                logger.info(f"â³ [{self.session_id}] ì§„í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ ëŒ€ê¸° ì¤‘...")
                try:
                    result = await self.current_task
                    question = self.current_question.strip()

                    logger.info(f"ğŸ‰ [{self.session_id}] EOS ì²˜ë¦¬ ì™„ë£Œ! ì§ˆë¬¸: '{question}'")

                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                    if question and result.get("content"):
                        self.conversation_history.append({
                            "role": "user",
                            "content": question
                        })
                        self.conversation_history.append({
                            "role": "assistant", 
                            "content": result.get("content")
                        })
                        
                        # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ (ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ ìœ ì§€)
                        if len(self.conversation_history) > 20:
                            self.conversation_history = self.conversation_history[-20:]

                    # EOS ì²˜ë¦¬ ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™” (TTS ì „ì†¡ ì „ì—)
                    self.current_question = ""
                    self.is_eos_received = False
                    self.current_task = None

                    return {
                        "type": "complete",
                        "content": result.get("content", ""),
                        "question": question,
                        "message": "EOSë¡œ ì¸í•œ ì™„ì „í•œ ë‹µë³€ ì™„ë£Œ",  # ğŸ”¥ TTS ì „ì†¡ êµ¬ë¶„ìš© ë©”ì‹œì§€
                        "timestamp": datetime.now().isoformat(),
                        "processing_stats": result.get("processing_stats", {}),
                        "model_used": f"Qwen {self.model_name}",
                        "tts_required": True  # ğŸ”¥ TTS ì „ì†¡ í•„ìš” í”Œë˜ê·¸
                    }
                except Exception as e:
                    logger.error(f"âŒ [{self.session_id}] EOS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    return {
                        "type": "error",
                        "error": str(e),
                        "timestamp": datetime.now().isoformat(),
                        "model_used": f"Qwen {self.model_name}"
                    }
            else:
                # ì§„í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ê°€ ì—†ëŠ” ê²½ìš° - ë§ˆì§€ë§‰ ì™„ë£Œëœ ì‘ë‹µ ë°˜í™˜
                if self.last_completed_response:
                    logger.info(f"ğŸ“ [{self.session_id}] ì§„í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ ì—†ìŒ, ë§ˆì§€ë§‰ ì™„ë£Œëœ ì‘ë‹µ ë°˜í™˜")

                    # ë§ˆì§€ë§‰ ì™„ë£Œëœ ì‘ë‹µ ë°˜í™˜ í›„ current_question ì´ˆê¸°í™”
                    question = self.last_completed_question
                    self.current_question = ""
                    self.is_eos_received = False

                    return {
                        "type": "complete",
                        "content": self.last_completed_response,
                        "question": question,
                        "message": "ë§ˆì§€ë§‰ ì™„ë£Œëœ ì‘ë‹µ ë°˜í™˜",
                        "timestamp": datetime.now().isoformat(),
                        "model_used": f"Qwen {self.model_name}",
                        "tts_required": False  # ğŸ”¥ TTS ì „ì†¡ ë¶ˆí•„ìš”
                    }
                else:
                    logger.info(f"â“ [{self.session_id}] ì™„ë£Œëœ ì‘ë‹µì´ ì—†ì–´ì„œ ë¹ˆ ì‘ë‹µ ì²˜ë¦¬")

                    # ë¹ˆ ì‘ë‹µ ì²˜ë¦¬ ì‹œì—ë„ current_question ì´ˆê¸°í™”
                    question = self.current_question.strip()
                    self.current_question = ""
                    self.is_eos_received = False

                    return {
                        "type": "complete",
                        "content": "ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                        "question": question,
                        "message": "ì™„ë£Œëœ ì‘ë‹µ ì—†ì´ EOS ìˆ˜ì‹ ",
                        "timestamp": datetime.now().isoformat(),
                        "model_used": f"Qwen {self.model_name}",
                        "tts_required": False  # ğŸ”¥ TTS ì „ì†¡ ë¶ˆí•„ìš”
                    }
        else:
            # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì‘ë‹µì´ ìˆìœ¼ë©´ ì¤‘ë‹¨
            if self.current_task and not self.current_task.done():
                logger.info(f"ğŸ›‘ [{self.session_id}] ì´ì „ íƒœìŠ¤í¬ ì¤‘ë‹¨ ì‹œì‘...")
                self.current_task.cancel()
                self.cancel_event.set()

                try:
                    await self.current_task
                    logger.info(f"âœ… [{self.session_id}] ì´ì „ íƒœìŠ¤í¬ ì¤‘ë‹¨ ì™„ë£Œ")
                except asyncio.CancelledError:
                    logger.info(f"ğŸ”„ [{self.session_id}] ì´ì „ íƒœìŠ¤í¬ ì·¨ì†Œë¨")

            # í† í°ì„ í˜„ì¬ ì§ˆë¬¸ì— ì¶”ê°€
            old_question = self.current_question
            self.current_question += token
            self.cancel_event.clear()
            self.is_eos_received = False

            logger.info(f"ğŸ“Š [{self.session_id}] ì§ˆë¬¸ ì—…ë°ì´íŠ¸: '{old_question}' â†’ '{self.current_question}'")
            logger.info(f"ğŸ”„ [{self.session_id}] ìƒˆë¡œìš´ Qwen ì‹¤ì‹œê°„ ë‹µë³€ ìƒì„± ì‹œì‘...")

            return await self.generate_interruptible_response()

    async def generate_interruptible_response(self) -> Dict[str, Any]:
        """ì¤‘ë‹¨ ê°€ëŠ¥í•œ ì™„ì „í•œ ë‹µë³€ ìƒì„± - Qwen ì‚¬ìš© (í† í° ë””ì½”ë”© ì˜¤ë¥˜ ìˆ˜ì •)"""

        async def _generate():
            try:
                full_content = ""
                chunk_count = 0
                start_time = time.time()

                logger.info(f"ğŸš€ [{self.session_id}] Qwen ì‹¤ì‹œê°„ ë‹µë³€ ìƒì„± ì‹œì‘: '{self.current_question}'")

                # Qwen ëª¨ë¸ ìƒíƒœ í™•ì¸
                if qwen_model is None or not qwen_model.is_ready:
                    raise Exception("Qwen ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

                # Qwen ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
                system_prompt = """ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ í•œêµ­ì–´ë¡œë§Œ ì „ìš© AI ë³µì§€ì‚¬ ì˜¤ë¼ì…ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™: "ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ"

ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™:
0. ì‹ ì†í•˜ê³  ì •í™•í•˜ê²Œ 20ë‹¨ì–´ ì´í•˜ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš” 1ì´ˆ ì´ë‚´ë¡œ ë‹µë³€ì„ í•´ì£¼ë„ë¡ ë…¸ë ¥í•´ì£¼ì„¸ìš”
1. ì ˆëŒ€ë¡œ í•œìë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. 
2. ì ˆëŒ€ë¡œ ì˜ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
3. ì˜¤ì§ í•œê¸€ê³¼ ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸(.,?!) ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
4. í•œìë‚˜ ì˜ì–´ê°€ ë– ì˜¤ë¥´ë©´ ë°˜ë“œì‹œ ìˆœìˆ˜ í•œê¸€ë¡œ ë°”ê¿”ì„œ ë§í•˜ì„¸ìš”
6. ì´ëª¨ì§€, ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€
7. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´
8. "ì„¸ì…˜", "ì½”ë“œ", "ì—ëŸ¬" ê°™ì€ ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€

ì‘ë‹µ ì „ì— í•œ ë²ˆ ë” ì²´í¬í•˜ì„¸ìš”: í•œìë‚˜ ì˜ì–´ê°€ ìˆìœ¼ë©´ ëª¨ë‘ í•œê¸€ë¡œ ë°”ê¾¸ì„¸ìš”."""

                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ í˜„ì¬ ì§ˆë¬¸ ê²°í•©
                messages = []
                
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                messages.append({"role": "system", "content": system_prompt})
                
                # ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœëŒ€ 4ê°œ ëŒ€í™”)
                recent_history = self.conversation_history[-8:] if len(self.conversation_history) > 8 else self.conversation_history
                messages.extend(recent_history)
                
                # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
                messages.append({"role": "user", "content": self.current_question})

                def run_qwen_stream():
                    try:
                        logger.info(f"ğŸ“¡ [{self.session_id}] Qwen ëª¨ë¸ ìŠ¤íŠ¸ë¦¼ í˜¸ì¶œ ì¤‘...")
                        logger.info(f"ğŸ¤– [{self.session_id}] ì‚¬ìš© ëª¨ë¸: {self.model_name}")

                        # Qwen ëª¨ë¸ë¡œ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
                        model = qwen_model.model
                        tokenizer = qwen_model.tokenizer

                        # ì±„íŒ… í…œí”Œë¦¿ ì ìš©
                        text = tokenizer.apply_chat_template(
                            messages,
                            tokenize=False,
                            add_generation_prompt=True
                        )

                        # í† í¬ë‚˜ì´ì§•
                        inputs = tokenizer(text, return_tensors="pt").to(model.device)

                        # ìŠ¤íŠ¸ë¦¬ë° ìƒì„± - ìˆ˜ì •ëœ ë²„ì „
                        with torch.no_grad():
                            for i in range(50):  # ìµœëŒ€ 50ê°œ í† í° ìƒì„±
                                if self.cancel_event.is_set() and not self.is_eos_received:
                                    logger.warning(f"âš ï¸ [{self.session_id}] ì¤‘ë‹¨ ì´ë²¤íŠ¸ ê°ì§€ - Qwen ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ")
                                    break

                                # ë‹¤ìŒ í† í° ìƒì„±
                                outputs = model.generate(
                                    inputs.input_ids,
                                    max_new_tokens=1,
                                    do_sample=True,
                                    temperature=0.3,
                                    top_p=0.8,
                                    use_cache=True,
                                    pad_token_id=tokenizer.eos_token_id,
                                    eos_token_id=tokenizer.eos_token_id
                                )

                                # ìƒˆë¡œ ìƒì„±ëœ í† í° ID ì¶”ì¶œ
                                new_token_ids = outputs[0][inputs.input_ids.shape[1]:]
                                if len(new_token_ids) == 0:
                                    logger.debug(f"[{self.session_id}] ìƒˆë¡œìš´ í† í°ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                                    break

                                # í† í° IDë¥¼ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”© - ì˜¤ë¥˜ ìˆ˜ì • ë¶€ë¶„
                                try:
                                    new_token = tokenizer.decode(new_token_ids, skip_special_tokens=True)
                                    
                                    # ë¹ˆ í† í°ì´ê±°ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                                    if not new_token or new_token.isspace():
                                        logger.debug(f"[{self.session_id}] ë¹ˆ í† í° ë˜ëŠ” ê³µë°± í† í° ìŠ¤í‚µ")
                                        continue
                                    
                                    # í† í°ì´ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                                    if not isinstance(new_token, str):
                                        logger.warning(f"[{self.session_id}] í† í°ì´ ë¬¸ìì—´ì´ ì•„ë‹˜: {type(new_token)} - {new_token}")
                                        new_token = str(new_token)  # ê°•ì œë¡œ ë¬¸ìì—´ ë³€í™˜
                                    
                                    logger.debug(f"[{self.session_id}] ìƒì„±ëœ í† í°: '{new_token}' (íƒ€ì…: {type(new_token)})")
                                    
                                except Exception as decode_error:
                                    logger.error(f"[{self.session_id}] í† í° ë””ì½”ë”© ì˜¤ë¥˜: {decode_error}")
                                    logger.error(f"[{self.session_id}] ë¬¸ì œ í† í° ID: {new_token_ids}")
                                    continue

                                # EOS í† í° ì²´í¬
                                if len(new_token_ids) > 0 and new_token_ids[-1].item() == tokenizer.eos_token_id:
                                    logger.info(f"[{self.session_id}] EOS í† í° ê°ì§€, ìƒì„± ì¤‘ë‹¨")
                                    break

                                # ë‹¤ìŒ ìƒì„±ì„ ìœ„í•´ ì…ë ¥ ì—…ë°ì´íŠ¸
                                inputs.input_ids = outputs[0:1]
                                
                                # ì„±ê³µì ìœ¼ë¡œ ë””ì½”ë”©ëœ í† í° ë°˜í™˜
                                yield new_token

                                # ì™„ë£Œ ì¡°ê±´ ì²´í¬ (ë‹¨ì–´ ìˆ˜ ê¸°ì¤€)
                                current_words = new_token.split() if new_token else []
                                if len(current_words) >= 20:  # 20ë‹¨ì–´ ì œí•œ
                                    logger.info(f"[{self.session_id}] 20ë‹¨ì–´ ì œí•œ ë„ë‹¬, ìƒì„± ì¤‘ë‹¨")
                                    break

                    except Exception as e:
                        logger.error(f"âŒ [{self.session_id}] Qwen ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜: {e}")
                        logger.error(f"âŒ [{self.session_id}] ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}")
                        import traceback
                        logger.error(f"âŒ [{self.session_id}] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                        yield ""

                # ìŠ¤íŠ¸ë¦¼ì—ì„œ í† í°ë“¤ì„ ìˆ˜ì§‘
                for chunk in run_qwen_stream():
                    if not self.is_eos_received:
                        if self.cancel_event.is_set():
                            logger.warning(f"ğŸ›‘ [{self.session_id}] ìƒˆë¡œìš´ í† í°ìœ¼ë¡œ ì¸í•œ ì¤‘ë‹¨ ìš”ì²­")
                            raise asyncio.CancelledError("ìƒˆë¡œìš´ í† í°ìœ¼ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨")

                    if chunk and isinstance(chunk, str):  # ë¬¸ìì—´ì¸ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸
                        chunk_count += 1
                        try:
                            full_content += chunk
                            logger.debug(f"[{self.session_id}] ì²­í¬ {chunk_count} ì¶”ê°€: '{chunk}' (ëˆ„ì : {len(full_content)}ì)")
                        except Exception as concat_error:
                            logger.error(f"âŒ [{self.session_id}] ë¬¸ìì—´ ì—°ê²° ì˜¤ë¥˜: {concat_error}")
                            logger.error(f"âŒ [{self.session_id}] full_content íƒ€ì…: {type(full_content)}, chunk íƒ€ì…: {type(chunk)}")
                            continue
                        
                        # Qwen ìŠ¤íŠ¸ë¦¼ ì§„í–‰ìƒí™© ë¡œê¹…
                        if chunk_count % 5 == 0:
                            logger.debug(f"ğŸ”„ [{self.session_id}] Qwen ì²­í¬ {chunk_count}ê°œ ì²˜ë¦¬ë¨")

                    # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                    await asyncio.sleep(0.01)

                elapsed_time = time.time() - start_time
                logger.info(f"âœ… [{self.session_id}] Qwen ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ! ì´ {chunk_count}ê°œ ì²­í¬, {elapsed_time:.2f}ì´ˆ ì†Œìš”")
                logger.info(f"ğŸ“„ [{self.session_id}] ìµœì¢… ì‘ë‹µ ê¸¸ì´: {len(full_content)}ì")
                logger.info(f"ğŸ¯ [{self.session_id}] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: '{full_content[:100]}{'...' if len(full_content) > 100 else ''}'")
                if elapsed_time > 0:
                    logger.info(f"âš¡ [{self.session_id}] Qwen í‰ê·  ì†ë„: {chunk_count/elapsed_time:.1f} ì²­í¬/ì´ˆ")

                # ì™„ë£Œëœ ì‘ë‹µì„ ì €ì¥
                if full_content.strip():
                    self.last_completed_response = full_content.strip()
                    self.last_completed_question = self.current_question
                    logger.info(f"ğŸ’¾ [{self.session_id}] Qwen ì™„ë£Œëœ ì‘ë‹µ ì €ì¥ë¨")

                return {
                    "type": "interrupted" if not self.is_eos_received else "complete",
                    "content": full_content.strip(),
                    "current_question": self.current_question,
                    "timestamp": datetime.now().isoformat(),
                    "model_used": f"Qwen {self.model_name}",
                    "processing_stats": {
                        "chunk_count": chunk_count,
                        "elapsed_time": round(elapsed_time, 2),
                        "content_length": len(full_content),
                        "avg_chunks_per_second": round(chunk_count/elapsed_time, 2) if elapsed_time > 0 else 0,
                        "provider": "Qwen",
                        "gpu_memory_used": torch.cuda.memory_allocated() / 1024**3 if torch.cuda.is_available() else 0
                    }
                }

            except asyncio.CancelledError:
                elapsed_time = time.time() - start_time if 'start_time' in locals() else 0
                logger.warning(f"ğŸ”„ [{self.session_id}] Qwen ë‹µë³€ì´ ìƒˆë¡œìš´ í† í°ìœ¼ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨ ({elapsed_time:.2f}ì´ˆ í›„)")
                logger.info(f"ğŸ“Š [{self.session_id}] ì¤‘ë‹¨ ì‹œì  í†µê³„: {chunk_count if 'chunk_count' in locals() else 0}ê°œ ì²­í¬ ì²˜ë¦¬ë¨")
                return {
                    "type": "aborted",
                    "message": "ìƒˆë¡œìš´ ì…ë ¥ìœ¼ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨",
                    "partial_content": full_content if 'full_content' in locals() else "",
                    "timestamp": datetime.now().isoformat(),
                    "model_used": f"Qwen {self.model_name}",
                    "processing_stats": {
                        "chunk_count": chunk_count if 'chunk_count' in locals() else 0,
                        "elapsed_time": round(elapsed_time, 2),
                        "content_length": len(full_content) if 'full_content' in locals() else 0,
                        "provider": "Qwen"
                    }
                }
            except Exception as error:
                elapsed_time = time.time() - start_time if 'start_time' in locals() else 0
                logger.error(f"ğŸ’¥ [{self.session_id}] Qwen ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {error} ({elapsed_time:.2f}ì´ˆ í›„)")

                # Qwen íŠ¹í™” ì—ëŸ¬ ì²˜ë¦¬
                error_type = "unknown"
                if "cuda" in str(error).lower() or "gpu" in str(error).lower():
                    error_type = "gpu_error"
                elif "memory" in str(error).lower():
                    error_type = "memory_error"
                elif "model" in str(error).lower():
                    error_type = "model_error"
                elif "timeout" in str(error).lower():
                    error_type = "timeout"
                elif "concatenate" in str(error).lower():
                    error_type = "string_concatenation_error"

                return {
                    "type": "error",
                    "error": str(error),
                    "error_type": error_type,
                    "timestamp": datetime.now().isoformat(),
                    "model_used": f"Qwen {self.model_name}",
                    "processing_stats": {
                        "chunk_count": chunk_count if 'chunk_count' in locals() else 0,
                        "elapsed_time": round(elapsed_time, 2),
                        "provider": "Qwen"
                    }
                }

        logger.info(f"ğŸ¬ [{self.session_id}] Qwen ë¹„ë™ê¸° íƒœìŠ¤í¬ ìƒì„± ë° ì‹œì‘")
        self.current_task = asyncio.create_task(_generate())
        return await self.current_task

    def reset(self):
        """í˜„ì¬ ìƒíƒœ ì´ˆê¸°í™”"""
        if self.current_task and not self.current_task.done():
            self.current_task.cancel()
        self.current_question = ""
        self.current_task = None
        self.cancel_event.clear()
        self.is_eos_received = False
        logger.info("Qwen í”„ë¡œì„¸ì„œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")


sys.path.append(os.path.join(os.path.dirname(__file__), '../../../..'))
try:
    from shared.infrastructure.http_client import http_client
except ImportError:
    import requests
    http_client = None

class ChatConsumer(AsyncWebsocketConsumer):
    """Django Channels WebSocket Consumer for Chat - Qwen ë²„ì „"""

    # í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì˜ í”„ë¡œì„¸ì„œ ê´€ë¦¬
    processors = {}

    async def connect(self):
        """WebSocket ì—°ê²° ìˆ˜ë½"""
        try:
            headers = dict(self.scope['headers'])
            phone_Id = headers.get(b'phone-id', b'').decode()
            session_Id = headers.get(b'session-id', b'').decode()

            await self.accept()

            self.phone_Id = phone_Id or f"unknown_{id(self)}"  # ğŸ”¥ ê¸°ë³¸ê°’ ì„¤ì •
            self.session_id = session_Id or f"session_{id(self)}"  # ğŸ”¥ ê¸°ë³¸ê°’ ì„¤ì •
            self.is_connected = True  # ğŸ”¥ ì—°ê²° ìƒíƒœ í”Œë˜ê·¸ ì¶”ê°€

            logger.info(f"ğŸ”— ìƒˆ Qwen í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {self.phone_Id} (ì„¸ì…˜: {self.session_id})")

            # Qwen í”„ë¡œì„¸ì„œ ìƒì„±
            processor = QwenStreamProcessor(session_id=self.session_id)
            ChatConsumer.processors[self.phone_Id] = processor

            # ì—°ê²° í™•ì¸ ë©”ì‹œì§€ ì „ì†¡ - Qwen ì •ë³´ í¬í•¨
            await self.safe_send({
                "type": "connection_established",
                "phone_Id": self.phone_Id,
                "session_id": self.session_id,
                "message": "Qwen WebSocket ì—°ê²°ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "model_info": {
                    "provider": "Qwen",
                    "model": processor.model_name,
                    "features": ["ë¡œì»¬ ì¶”ë¡ ", "ìŠ¤íŠ¸ë¦¬ë°", "ëŒ€í™” ê¸°ë¡", "í•œêµ­ì–´ íŠ¹í™”"],
                    "gpu_available": torch.cuda.is_available(),
                    "model_ready": qwen_model.is_ready if qwen_model else False
                },
                "timestamp": datetime.now().isoformat()
            })

            logger.info(f"[{self.phone_Id}] Qwen ì—°ê²° ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ WebSocket ì—°ê²° ì¤‘ ì˜¤ë¥˜: {e}")
            self.is_connected = False
            try:
                await self.close()
            except:
                pass

    async def disconnect(self, close_code):
        """WebSocket ì—°ê²° í•´ì œ"""
        phone_id = getattr(self, 'phone_Id', 'Unknown')
        logger.info(f"Qwen í´ë¼ì´ì–¸íŠ¸ {phone_id} ì—°ê²° ì¢…ë£Œ (ì½”ë“œ: {close_code})")
        self.is_connected = False  # ğŸ”¥ ì—°ê²° ìƒíƒœ falseë¡œ ë³€ê²½
        await self.cleanup_client()

    async def receive(self, text_data):
        """ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬"""
        phone_id = getattr(self, 'phone_Id', 'Unknown')
        logger.info(f"[{phone_id}] Qwen ì›ë³¸ ë©”ì‹œì§€ ìˆ˜ì‹ : {repr(text_data)}")

        try:
            # JSON ë©”ì‹œì§€ íŒŒì‹±
            data = json.loads(text_data)
            logger.info(f"[{phone_id}] JSON íŒŒì‹± ì„±ê³µ: {data}")
            await self.handle_json_message(data)

        except Exception as e:
            logger.error(f"[{phone_id}] Qwen ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            await self.safe_send_error(str(e))

    async def handle_json_message(self, data: dict):
        """JSON í˜•ì‹ ë©”ì‹œì§€ ì²˜ë¦¬"""
        if data.get("token"):
            # í† í° ì²˜ë¦¬
            token = data.get("token", "")
            request_Id = data.get("request_id", "")
            phone_id = getattr(self, 'phone_Id', 'Unknown')
            logger.info(f"[{phone_id}] Qwen í† í° ì²˜ë¦¬: '{token}' , request_Id ì²˜ë¦¬: '{request_Id}'")

            # ë¹„ë™ê¸°ë¡œ í† í° ì²˜ë¦¬
            asyncio.create_task(
                self.process_token_and_respond(token, request_Id)
            )

    async def safe_send(self, data: dict):
        """ì•ˆì „í•œ ë©”ì‹œì§€ ì „ì†¡ - ì—°ê²° ìƒíƒœ í™•ì¸"""
        if not hasattr(self, 'is_connected') or not self.is_connected:
            phone_id = getattr(self, 'phone_Id', 'Unknown')
            logger.warning(f"[{phone_id}] WebSocket ì—°ê²°ì´ ì´ë¯¸ ëŠì–´ì§ - ë©”ì‹œì§€ ì „ì†¡ ìŠ¤í‚µ")
            return False
            
        try:
            await self.send(text_data=json.dumps(data, ensure_ascii=False))
            return True
        except RuntimeError as e:
            if "websocket.close" in str(e) or "response already completed" in str(e):
                phone_id = getattr(self, 'phone_Id', 'Unknown')
                logger.warning(f"[{phone_id}] WebSocket ì´ë¯¸ ë‹«í˜ - ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸")
                self.is_connected = False
                return False
            else:
                phone_id = getattr(self, 'phone_Id', 'Unknown')
                logger.error(f"[{phone_id}] ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜: {e}")
                raise e
        except Exception as e:
            phone_id = getattr(self, 'phone_Id', 'Unknown')
            logger.error(f"[{phone_id}] ì˜ˆìƒì¹˜ ëª»í•œ ì „ì†¡ ì˜¤ë¥˜: {e}")
            self.is_connected = False
            return False

    async def process_token_and_respond(self, token: str, request_Id: str):
        """í† í°ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ì „ì†¡ - ì—°ê²° ìƒíƒœ í™•ì¸ ì¶”ê°€"""
        try:
            # ğŸ”¥ ì—°ê²° ìƒíƒœ ì‚¬ì „ í™•ì¸
            if not hasattr(self, 'is_connected') or not self.is_connected:
                logger.warning(f"[{getattr(self, 'phone_Id', 'Unknown')}] WebSocket ì—°ê²° ëŠì–´ì§ - í† í° ì²˜ë¦¬ ì¤‘ë‹¨")
                return

            processor = ChatConsumer.processors.get(self.phone_Id)
            if not processor:
                logger.error(f"[{self.phone_Id}] Qwen í”„ë¡œì„¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await self.safe_send_error("Qwen í”„ë¡œì„¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            start_time = time.time()
            logger.info(f"ğŸ® [{self.phone_Id}] Qwen í† í° ì²˜ë¦¬ ì‹œì‘: '{token}'")

            # ğŸ”¥ ë¹ˆ í† í°ì´ë‚˜ ì´ìƒí•œ í† í° ì²´í¬
            if not token or token.strip() == '':
                logger.warning(f"[{self.phone_Id}] ë¹ˆ í† í° ìˆ˜ì‹  - ì²˜ë¦¬ ìŠ¤í‚µ")
                return

            result = await processor.process_stream_token(token)
            processing_time = time.time() - start_time

            # ğŸ”¥ ì—°ê²° ìƒíƒœ ì¬í™•ì¸
            if not hasattr(self, 'is_connected') or not self.is_connected:
                logger.warning(f"[{self.phone_Id}] ì²˜ë¦¬ ì™„ë£Œ í›„ ì—°ê²° í™•ì¸ ì‹¤íŒ¨ - ì‘ë‹µ ì „ì†¡ ìŠ¤í‚µ")
                return

            # ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
            response = {
                "phone_Id": self.phone_Id,
                "token_received": token,
                "processing_time": round(processing_time, 3),
                "provider": "Qwen",
                **result
            }

            # ğŸ”¥ ì•ˆì „í•œ ì „ì†¡ ì‚¬ìš©
            send_success = await self.safe_send(response)
            if not send_success:
                logger.warning(f"[{self.phone_Id}] ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨ - ì—°ê²° ëŠì–´ì§")
                return

            # ğŸ”¥ TTS ì „ì†¡ì€ tts_requiredê°€ Trueì¸ ê²½ìš°ì—ë§Œ ì‹¤í–‰
            if (result["type"] == "complete" and 
                result.get("tts_required", False) and
                result.get('content', '').strip()):
                
                # ğŸ”¥ TTS ì „ì†¡ ì „ì—ë„ ì—°ê²° ìƒíƒœ í™•ì¸
                if not hasattr(self, 'is_connected') or not self.is_connected:
                    logger.warning(f"[{self.phone_Id}] TTS ì „ì†¡ ì „ ì—°ê²° í™•ì¸ ì‹¤íŒ¨")
                    return

                # ğŸ”¥ ë¹ˆ ë‹µë³€ì´ë‚˜ ë„ˆë¬´ ì§§ì€ ë‹µë³€ì€ TTS ìŠ¤í‚µ
                content = result.get('content', '').strip()
                if not content or len(content) < 2:
                    logger.warning(f"[{self.phone_Id}] ë‹µë³€ì´ ë„ˆë¬´ ì§§ì•„ì„œ TTS ìŠ¤í‚µ: '{content}'")
                    return

                tts_message = {
                    'phoneId': self.phone_Id,
                    'sessionId': self.session_id,
                    'requestId': request_Id,
                    'voice_config': {'language': 'ko'},
                    'text': content
                }

                stats = result.get("processing_stats", {})
                logger.info(f"ğŸ‰ [{self.phone_Id}] Qwen ìµœì¢… ë‹µë³€ ì™„ë£Œ - TTS ì „ì†¡!")
                logger.info(f"ğŸ“ ì§ˆë¬¸: '{result.get('question', '')}'")
                logger.info(f"ğŸ“„ ë‹µë³€ ê¸¸ì´: {len(content)}ì")
                logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")

                # TTS ì „ì†¡ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ë˜ ì—ëŸ¬ ì²˜ë¦¬)
                asyncio.create_task(self.safe_send_to_tts(tts_message))
                
            elif result["type"] == "complete":
                # ë‹¤ë¥¸ complete íƒ€ì…ë“¤ì€ ë¡œê·¸ë§Œ ì¶œë ¥
                logger.info(f"ğŸ“ [{self.phone_Id}] ë‹µë³€ ì™„ë£Œ (TTS ìŠ¤í‚µ): {result.get('message', '')}")
                logger.info(f"ğŸ“„ ë‹µë³€ ë‚´ìš©: '{result.get('content', '')[:50]}...'")
                
            elif result["type"] == "aborted":
                stats = result.get("processing_stats", {})
                logger.warning(f"ğŸ’” [{self.phone_Id}] Qwen ë‹µë³€ ì¤‘ë‹¨ë¨")
                logger.info(f"â±ï¸ ì¤‘ë‹¨ê¹Œì§€ ì‹œê°„: {processing_time:.3f}ì´ˆ")
                if stats:
                    logger.info(f"ğŸ“Š ì¤‘ë‹¨ ì‹œì  í†µê³„: {stats}")

            elif result["type"] == "interrupted":
                logger.info(f"âš¡ [{self.phone_Id}] Qwen ì‹¤ì‹œê°„ ë‹µë³€ ì§„í–‰ ì¤‘...")
                logger.info(f"â±ï¸ í˜„ì¬ê¹Œì§€ ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")

            elif result["type"] == "error":
                error_type = result.get("error_type", "unknown")
                logger.error(f"âŒ [{self.phone_Id}] Qwen ì²˜ë¦¬ ì˜¤ë¥˜ ({error_type}): {result.get('error', '')}")
                logger.info(f"â±ï¸ ì˜¤ë¥˜ ë°œìƒê¹Œì§€ ì‹œê°„: {processing_time:.3f}ì´ˆ")

        except Exception as e:
            processing_time = time.time() - start_time if 'start_time' in locals() else 0
            logger.error(f"ğŸ’¥ [{getattr(self, 'phone_Id', 'Unknown')}] Qwen í† í° ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            logger.info(f"â±ï¸ ì˜ˆì™¸ ë°œìƒê¹Œì§€ ì‹œê°„: {processing_time:.3f}ì´ˆ")
            # ğŸ”¥ ì˜ˆì™¸ ì²˜ë¦¬ ì‹œ ì—°ê²° ìƒíƒœ í™•ì¸ í›„ ì—ëŸ¬ ì „ì†¡
            if hasattr(self, 'is_connected') and self.is_connected:
                try:
                    await self.safe_send_error(str(e))
                except:
                    logger.error(f"[{getattr(self, 'phone_Id', 'Unknown')}] ì—ëŸ¬ ì‘ë‹µ ì „ì†¡ë„ ì‹¤íŒ¨")

    async def safe_send_error(self, error_message: str):
        """ì•ˆì „í•œ ì˜¤ë¥˜ ì‘ë‹µ ì „ì†¡"""
        phone_id = getattr(self, 'phone_Id', 'Unknown')
        if not hasattr(self, 'is_connected') or not self.is_connected:
            logger.warning(f"[{phone_id}] ì—°ê²° ëŠì–´ì§ - ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ì†¡ ìŠ¤í‚µ")
            return

        await self.safe_send({
            "type": "error",
            "error": error_message,
            "phone_Id": phone_id,
            "provider": "Qwen",
            "timestamp": datetime.now().isoformat()
        })

    async def cleanup_client(self):
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì •ë¦¬"""
        phone_id = getattr(self, 'phone_Id', 'Unknown')
        if hasattr(self, 'phone_Id') and self.phone_Id in ChatConsumer.processors:
            processor = ChatConsumer.processors[self.phone_Id]
            processor.reset()  # ì§„í–‰ ì¤‘ì¸ ì‘ì—… ì •ë¦¬
            del ChatConsumer.processors[self.phone_Id]
            logger.info(f"Qwen í´ë¼ì´ì–¸íŠ¸ {phone_id} ì •ë¦¬ ì™„ë£Œ")

    async def safe_send_to_tts(self, tts_message: Dict[str, Any]):
        """TTS ì „ì†¡ - ì—°ê²° ìƒíƒœ ë¬´ê´€í•˜ê²Œ ì‹¤í–‰"""
        try:
            result = await self.send_to_tts_server(tts_message)
            phone_id = getattr(self, 'phone_Id', 'Unknown')
            logger.info(f"ğŸ“¡ [{phone_id}] TTS ì „ì†¡ ê²°ê³¼: {result.get('success', False)}")
        except Exception as e:
            phone_id = getattr(self, 'phone_Id', 'Unknown')
            logger.error(f"âŒ [{phone_id}] TTS ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    async def send_to_tts_server(self, tts_message: Dict[str, Any]) -> Dict[str, Any]:
        """TTS ì„œë²„ë¡œ HTTP POST ì „ì†¡ - Qwen ë²„ì „"""
        self.tts_server_url = getattr(settings, 'TTS_SERVER_URL', 'http://tts_server:5002')
        
        try:
            tts_url = f"{self.tts_server_url}/api/convert-tts/"

            # ì „ì†¡í•  ë°ì´í„° ë¡œê¹…
            logger.info(f"ğŸ“¤ [Qwen LLM Workflow] TTS ì„œë²„ë¡œ HTTP ì „ì†¡: {tts_url}")
            logger.info(f"ğŸ“¦ [Qwen LLM Workflow] ì „ì†¡ ë°ì´í„°: {tts_message}")

            if http_client:
                response = http_client.post(tts_url, tts_message)
                return response
            else:
                import requests

                # í—¤ë”ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
                headers = {
                    'Content-Type': 'application/json',
                    'Accept': 'application/json'
                }

                response = requests.post(
                    tts_url,
                    json=tts_message,
                    headers=headers,
                    timeout=30,
                    verify=False
                )

                logger.info(f"ğŸ“¡ [Qwen LLM Workflow] ì‘ë‹µ ìƒíƒœì½”ë“œ: {response.status_code}")
                logger.info(f"ğŸ“„ [Qwen LLM Workflow] ì‘ë‹µ ë‚´ìš©: {response.text[:500]}")

                if response.status_code == 200:
                    logger.info("âœ… [Qwen LLM Workflow] TTS ì„œë²„ë¡œ ì „ì†¡ ì„±ê³µ!")
                    return {
                        'success': True,
                        'status_code': response.status_code,
                        'data': response.json() if response.content else None,
                        'llm_provider': 'Qwen'
                    }
                else:
                    logger.error(f"âŒ [Qwen LLM Workflow] TTS ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                    logger.error(f"ğŸ“„ [Qwen LLM Workflow] ì˜¤ë¥˜ ì‘ë‹µ: {response.text}")
                    return {
                        'success': False,
                        'status_code': response.status_code,
                        'error': response.text,
                        'llm_provider': 'Qwen'
                    }

        except Exception as e:
            logger.error(f"âŒ [Qwen LLM Workflow] TTS ì„œë²„ ì „ì†¡ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e),
                'llm_provider': 'Qwen'
            }