"""
âš¡ 500ms ì¦‰ì‹œ ì‘ë‹µ ì‹œìŠ¤í…œ
í•œë²ˆ ë¬¼ì–´ë³¸ ì§ˆë¬¸ì€ 500ms ì•ˆì— ë°”ë¡œ ì‘ë‹µ
"""
import os
import time
import logging
import hashlib
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from django.core.cache import cache

logger = logging.getLogger(__name__)

# ë¡œì»¬ ë©”ëª¨ë¦¬ ìºì‹œ (ê°€ì¥ ë¹ ë¦„)
_local_memory_cache = {}
_vector_response_cache = {}

class Instant500msLLM:
    """âš¡ 500ms ì¦‰ì‹œ ì‘ë‹µ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        # âš¡ ì´ˆê³ ì† LLM
        self.ultra_fast_llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            api_key=self.api_key,
            max_tokens=80,
            timeout=1,
            max_retries=0,
            request_timeout=0.8
        )

    async def get_instant_response(self, phone_id: str, user_text: str) -> str:
        """âš¡ 500ms ëª©í‘œ ì¦‰ì‹œ ì‘ë‹µ"""
        start_time = time.time()
        
        # 1. ğŸš€ ë¡œì»¬ ë©”ëª¨ë¦¬ ìºì‹œ (0.001ì´ˆ)
        local_cache_key = f"{phone_id}:{hash(user_text.lower().strip())}"
        if local_cache_key in _local_memory_cache:
            elapsed = time.time() - start_time
            logger.info(f"ğŸš€ ë¡œì»¬ ìºì‹œ: {elapsed*1000:.1f}ms")
            return _local_memory_cache[local_cache_key]

        # 2. ğŸ’¾ Redis ìºì‹œ (10ms)
        redis_cache_key = f"instant:{phone_id}:{hashlib.md5(user_text.encode()).hexdigest()}"
        cached = cache.get(redis_cache_key)
        if cached:
            # ë¡œì»¬ ìºì‹œì—ë„ ì €ì¥ (ë‹¤ìŒë²ˆ ë” ë¹ ë¥´ê²Œ)
            _local_memory_cache[local_cache_key] = cached
            elapsed = time.time() - start_time
            logger.info(f"ğŸ’¾ Redis ìºì‹œ: {elapsed*1000:.1f}ms")
            return cached

        # 3. ğŸ” ë²¡í„° DB ë¹ ë¥¸ ê²€ìƒ‰ ì‹œë„ (100ms ì œí•œ)
        vector_response = self._try_vector_search_fast(phone_id, user_text, max_time=0.1)
        if vector_response:
            # ëª¨ë“  ìºì‹œì— ì €ì¥
            self._save_to_all_caches(local_cache_key, redis_cache_key, vector_response)
            elapsed = time.time() - start_time
            logger.info(f"ğŸ” ë²¡í„° DB: {elapsed*1000:.1f}ms")
            return vector_response

        # 4. ğŸ¤– ì´ˆê³ ì† LLM ìƒì„± (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        try:
            messages = [
                SystemMessage(content="1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."),
                HumanMessage(content=user_text)
            ]
            
            response = await self.ultra_fast_llm.ainvoke(messages)
            result = response.content if response and response.content else "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤!"
            
            # ëª¨ë“  ìºì‹œì— ì €ì¥
            self._save_to_all_caches(local_cache_key, redis_cache_key, result)
            
            elapsed = time.time() - start_time
            logger.info(f"ğŸ¤– ìƒˆ ìƒì„±: {elapsed*1000:.1f}ms")
            return result
            
        except Exception as e:
            logger.error(f"ì´ˆê³ ì† LLM ì˜¤ë¥˜: {e}")
            return "ë„¤, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

    def _try_vector_search_fast(self, phone_id: str, user_text: str, max_time: float) -> Optional[str]:
        """ğŸ” 100ms ì œí•œ ë²¡í„° DB ê²€ìƒ‰"""
        start = time.time()
        
        try:
            # ë²¡í„° ê²€ìƒ‰ ì„í¬íŠ¸ëŠ” ì—¬ê¸°ì„œ (ì—ëŸ¬ ë°©ì§€)
            # from ..weaviate.weaviate_client import weaviate_client
            # import weaviate.classes as wvc
            
            if not weaviate_client or not weaviate_client.is_ready():
                return None
            
            # ì‹œê°„ ì œí•œ í™•ì¸
            if time.time() - start > max_time:
                return None
                
            conversations = weaviate_client.collections.get("Conversations")
            
            # ì´ˆê³ ì† ê²€ìƒ‰ (1ê°œë§Œ, ë†’ì€ ìœ ì‚¬ë„)
            search_results = conversations.query.near_text(
                query=user_text,
                limit=1,
                distance=0.1,  # ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„ (0.9 ì´ìƒ)
                where=wvc.query.Filter.by_property("phone_id").equal(phone_id),
                return_metadata=['distance'],
                return_properties=['ai_response']
            )
            
            # ì‹œê°„ ì œí•œ ì¬í™•ì¸
            if time.time() - start > max_time:
                return None
            
            if search_results.objects:
                best_match = search_results.objects[0]
                if hasattr(best_match, 'metadata') and best_match.metadata.distance <= 0.1:
                    ai_response = best_match.properties.get('ai_response')
                    if ai_response and len(ai_response.strip()) > 0:
                        return ai_response
                        
            return None
            
        except Exception as e:
            logger.warning(f"ë²¡í„° DB ê²€ìƒ‰ ìŠ¤í‚µ (ì˜¤ë¥˜): {e}")
            return None

    def _save_to_all_caches(self, local_key: str, redis_key: str, response: str):
        """ëª¨ë“  ìºì‹œì— ì €ì¥"""
        try:
            # ë¡œì»¬ ë©”ëª¨ë¦¬ ìºì‹œ (ê°€ì¥ ë¹ ë¦„)
            _local_memory_cache[local_key] = response
            
            # ë¡œì»¬ ìºì‹œ í¬ê¸° ì œí•œ (1000ê°œ)
            if len(_local_memory_cache) > 1000:
                # ê°€ì¥ ì˜¤ë˜ëœ 500ê°œ ì œê±°
                keys_to_remove = list(_local_memory_cache.keys())[:500]
                for key in keys_to_remove:
                    del _local_memory_cache[key]
            
            # Redis ìºì‹œ
            cache.set(redis_key, response, timeout=1800)  # 30ë¶„
            
        except Exception as e:
            logger.error(f"ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
instant_500ms_llm = Instant500msLLM()

# ë™ê¸° ë˜í¼ í•¨ìˆ˜
def start_chat_instant_500ms(phone_id: str, question: str) -> str:
    """500ms ì¦‰ì‹œ ì‘ë‹µ ë™ê¸° ë²„ì „"""
    import asyncio
    
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            result = loop.run_until_complete(
                instant_500ms_llm.get_instant_response(phone_id, question)
            )
            return result
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"500ms ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        # ì•ˆì „í•œ fallback
        return "ë„¤, ë§ì”€í•´ ì£¼ì„¸ìš”!" 