"""
ğŸ¯ ì»¤ì„œ AI - ë²¡í„° DB ìš°ì„  ê²€ìƒ‰ ì‹œìŠ¤í…œ
"Search First, Generate if Absent" ì›ì¹™ êµ¬í˜„
"""
import os
import time
import logging
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from django.core.cache import cache

# Weaviate ì§ì ‘ ì ‘ê·¼
# from ..weaviate.weaviate_client import weaviate_client
# import weaviate.classes as wvc

logger = logging.getLogger(__name__)

class VectorFirstLLM:
    """ğŸ¯ ë²¡í„° DB ìš°ì„  ê²€ìƒ‰ LLM ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.weaviate_client = weaviate_client
        
        # âš¡ ë¹ ë¥¸ LLM (fallbackìš©)
        self.fast_llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            api_key=self.api_key,
            max_tokens=100,
            timeout=2,
            max_retries=0,
            request_timeout=1.5
        )

    async def get_response_vector_first(self, phone_id: str, user_text: str) -> str:
        """ğŸ¯ ë²¡í„° DB ìš°ì„  ê²€ìƒ‰ â†’ ì¦‰ì‹œ ì‘ë‹µ"""
        start_time = time.time()
        
        # 1. ğŸ” ë²¡í„° DB ìš°ì„  ê²€ìƒ‰ (í•µì‹¬!)
        vector_response = self._search_vector_db_fast(phone_id, user_text)
        if vector_response:
            elapsed = time.time() - start_time
            logger.info(f"ğŸ¯ ë²¡í„° DB íˆíŠ¸: {elapsed:.3f}ì´ˆ")
            return vector_response

        # 2. ğŸ’¾ LLM ìºì‹œ í™•ì¸
        cache_key = f"llm_cache:{hash(user_text)}"
        cached = cache.get(cache_key)
        if cached:
            logger.info(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: {time.time() - start_time:.3f}ì´ˆ")
            return cached

        # 3. ğŸ¤– ìƒˆë¡œìš´ LLM ìƒì„± (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        try:
            messages = [
                SystemMessage(content="ê°„ê²°í•˜ê²Œ 1-2ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."),
                HumanMessage(content=user_text)
            ]
            
            response = await self.fast_llm.ainvoke(messages)
            result = response.content if response and response.content else "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤!"
            
            # ìºì‹± ë° ë²¡í„° DB ì €ì¥
            cache.set(cache_key, result, timeout=300)
            self._save_to_vector_db_async(phone_id, user_text, result)
            
            elapsed = time.time() - start_time
            logger.info(f"ğŸ¤– ìƒˆ ìƒì„±: {elapsed:.3f}ì´ˆ")
            return result
            
        except Exception as e:
            logger.error(f"LLM ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."

    def _search_vector_db_fast(self, phone_id: str, user_text: str) -> Optional[str]:
        """ğŸ” ë²¡í„° DB ì´ˆê³ ì† ê²€ìƒ‰"""
        try:
            if not self.weaviate_client or not self.weaviate_client.is_ready():
                return None
                
            # ğŸ¯ í° IDë³„ ëŒ€í™” ì»¬ë ‰ì…˜ ê²€ìƒ‰
            conversations = self.weaviate_client.collections.get("Conversations")
            
            # ğŸ¯ ì´ˆê³ ì† ìœ ì‚¬ë„ ê²€ìƒ‰ (ì„ê³„ê°’ 0.85 ì´ìƒ)
            search_results = conversations.query.near_text(
                query=user_text,
                limit=1,  # ê°€ì¥ ìœ ì‚¬í•œ 1ê°œë§Œ (ì†ë„ ìµœì í™”)
                distance=0.15,  # ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„ë§Œ (0.85 ì´ìƒ)
                where=wvc.query.Filter.by_property("phone_id").equal(phone_id),
                return_metadata=['distance'],  # ë©”íƒ€ë°ì´í„° ìµœì†Œí™”
                return_properties=['ai_response']  # í•„ìš”í•œ ì†ì„±ë§Œ ë°˜í™˜
            )
            
            if search_results.objects:
                # ê°€ì¥ ìœ ì‚¬í•œ ê²°ê³¼ì˜ ë‹µë³€ ë°˜í™˜
                best_match = search_results.objects[0]
                
                # ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸ (ê±°ë¦¬ê°€ 0.15 ì´í•˜ = ìœ ì‚¬ë„ 0.85 ì´ìƒ)
                if hasattr(best_match, 'metadata') and best_match.metadata.distance <= 0.15:
                    ai_response = best_match.properties.get('ai_response')
                    if ai_response and len(ai_response.strip()) > 0:
                        logger.info(f"ğŸ¯ ë²¡í„° DB ë§¤ì¹˜ ë°œê²¬: ìœ ì‚¬ë„ {1-best_match.metadata.distance:.3f}")
                        return ai_response
                        
            return None
            
        except Exception as e:
            logger.error(f"ë²¡í„° DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None

    def _save_to_vector_db_async(self, phone_id: str, user_text: str, ai_response: str):
        """ğŸ“ ë²¡í„° DBì— ìƒˆ ëŒ€í™” ë¹„ë™ê¸° ì €ì¥"""
        try:
            import threading
            
            def save_worker():
                try:
                    if not self.weaviate_client or not self.weaviate_client.is_ready():
                        return
                        
                    conversations = self.weaviate_client.collections.get("Conversations")
                    
                    conversations.data.insert({
                        "phone_id": phone_id,
                        "user_input": user_text,
                        "ai_response": ai_response,
                        "timestamp": time.time(),
                        "session_type": "vector_first"
                    })
                    
                    logger.info("ğŸ“ ë²¡í„° DB ì €ì¥ ì™„ë£Œ (ë°±ê·¸ë¼ìš´ë“œ)")
                    
                except Exception as e:
                    logger.error(f"ë²¡í„° DB ì €ì¥ ì˜¤ë¥˜: {e}")
            
            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì €ì¥
            thread = threading.Thread(target=save_worker)
            thread.daemon = True
            thread.start()
            
        except Exception as e:
            logger.error(f"ë²¡í„° DB ë¹„ë™ê¸° ì €ì¥ ì„¤ì • ì˜¤ë¥˜: {e}")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
vector_first_llm = VectorFirstLLM()

# ë™ê¸° ë˜í¼ í•¨ìˆ˜
def start_chat_vector_first(phone_id: str, question: str) -> str:
    """ë²¡í„° DB ìš°ì„  ê²€ìƒ‰ ë™ê¸° ë²„ì „"""
    import asyncio
    
    try:
        # ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            result = loop.run_until_complete(
                vector_first_llm.get_response_vector_first(phone_id, question)
            )
            return result
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"ë²¡í„° ìš°ì„  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”." 