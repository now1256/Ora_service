"""
ğŸš€ í˜„ì—… ë ˆë²¨ ìŠ¤íŠ¸ë¦¬ë° LangChain ì²˜ë¦¬
Cold Start ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìµœì í™”ëœ ìŠ¤íŠ¸ë¦¬ë° LLM
"""
import asyncio
import json
import time
import logging
from typing import Dict, Any, Optional, AsyncGenerator
from django.core.cache import cache
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.callbacks import AsyncCallbackHandler
import os

logger = logging.getLogger(__name__)

class StreamingCallback(AsyncCallbackHandler):
    """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.tokens = []
        self.start_time = time.time()
        
    async def on_llm_new_token(self, token: str, **kwargs) -> None:
        """ìƒˆ í† í° ìˆ˜ì‹ ì‹œ í˜¸ì¶œ"""
        self.tokens.append(token)
        
class OptimizedStreamingLLM:
    """ğŸš€ í˜„ì—…ìš© ìµœì í™” ìŠ¤íŠ¸ë¦¬ë° LLM"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        # ğŸš€ ì¤€ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° - ì²« í† í° ê·¹ì† (0.2ì´ˆ ëª©í‘œ)
        self.fast_llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            api_key=self.api_key,
            streaming=True,
            max_tokens=150,  # ì™„ì „í•œ ë‹µë³€ ë³´ì¥ (20 â†’ 150ì)
            timeout=3,       # ì•ˆì •ì„± í™•ë³´
            max_retries=0,   # ì¬ì‹œë„ ì—†ìŒ
            request_timeout=2  # ì•ˆì •ì  ìš”ì²­
        )
        
        # âš¡ ë°±ê·¸ë¼ìš´ë“œë„ ë¹ ë¥´ê²Œ (í•„ìš”ì‹œì—ë§Œ)
        self.accurate_llm = ChatOpenAI(
            model="gpt-4o-mini",  # ì •í™•ì„±ë³´ë‹¤ ì†ë„ ìš°ì„ 
            temperature=0,
            api_key=self.api_key,
            max_tokens=50,        # ë°±ê·¸ë¼ìš´ë“œë„ ì§§ê²Œ
            timeout=5,            # ë¹ ë¥¸ íƒ€ì„ì•„ì›ƒ
            max_retries=0         # ì¬ì‹œë„ ì—†ìŒ
        )
        
        # ìºì‹œ ì„¤ì •
        self.similarity_threshold = 0.88  # ìœ ì‚¬ë„ ì„ê³„ê°’
        self.cache_ttl = 900  # 15ë¶„

    async def get_instant_response(self, phone_id: str, user_text: str) -> Dict[str, Any]:
        """âš¡ ì¦‰ì‹œ ì‘ë‹µ (0.1ì´ˆ ì´ë‚´)"""
        
        start_time = time.time()
        
        # 1. ì™„ì „ ì¼ì¹˜ ìºì‹œ í™•ì¸
        exact_cache_key = f"llm_exact:{phone_id}:{hash(user_text)}"
        cached_response = cache.get(exact_cache_key)
        
        if cached_response:
            return {
                "content": cached_response,
                "source": "exact_cache",
                "processing_time": time.time() - start_time,
                "is_fast": True
            }
        
        # 2. ìœ ì‚¬ ìºì‹œ í™•ì¸ (ì„ë² ë”© ì—†ì´ í‚¤ì›Œë“œ ê¸°ë°˜)
        similar_response = self._check_keyword_cache(phone_id, user_text)
        if similar_response:
            return {
                "content": similar_response,
                "source": "similar_cache", 
                "processing_time": time.time() - start_time,
                "is_fast": True
            }
        
        
        # 4. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘
        return await self._start_streaming_response(phone_id, user_text)

    def _check_keyword_cache(self, phone_id: str, user_text: str) -> Optional[str]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ ìºì‹œ í™•ì¸"""
        try:
            # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(user_text.lower())
            
            # ìµœê·¼ 10ê°œ ìºì‹œì™€ í‚¤ì›Œë“œ ë§¤ì¹­
            for i in range(10):
                cache_key = f"llm_keyword:{phone_id}:{i}"
                cached_data = cache.get(cache_key)
                
                if cached_data:
                    cached_keywords = cached_data.get('keywords', [])
                    
                    # í‚¤ì›Œë“œ ë§¤ì¹­ë„ ê³„ì‚° (ê°„ë‹¨í•œ Jaccard ìœ ì‚¬ë„)
                    intersection = len(set(keywords) & set(cached_keywords))
                    union = len(set(keywords) | set(cached_keywords))
                    
                    if union > 0:
                        similarity = intersection / union
                        
                        if similarity > 0.6:  # 60% ì´ìƒ ìœ ì‚¬
                            logger.info(f"âš¡ í‚¤ì›Œë“œ ìœ ì‚¬ ìºì‹œ íˆíŠ¸: {similarity:.2f}")
                            return cached_data['response']
            
            return None
            
        except Exception as e:
            logger.warning(f"í‚¤ì›Œë“œ ìºì‹œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None

    def _extract_keywords(self, text: str) -> list:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë¶ˆìš©ì–´ ì œê±° ë° í‚¤ì›Œë“œ ì¶”ì¶œ
        stop_words = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ì™€', 'ê³¼', 'ì˜', 'ë¡œ', 'ìœ¼ë¡œ', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤'}
        words = text.split()
        
        # 2ê¸€ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì„ íƒ
        keywords = [word for word in words if len(word) >= 2 and word not in stop_words]
        
        return keywords[:5]  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ


    async def _start_streaming_response(self, phone_id: str, user_text: str) -> Dict[str, Any]:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘"""
        start_time = time.time()
        
        try:
            messages = [
                SystemMessage(content="ê°„ê²°í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."),
                HumanMessage(content=user_text)
            ]
            
            response_chunks = []
            full_response = ""
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            async for chunk in self.fast_llm.astream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    full_response += chunk.content
                    response_chunks.append(chunk.content)
            
            # ì‘ë‹µ ìºì‹±
            self._cache_response(phone_id, user_text, full_response)
            
            return {
                "content": full_response,
                "source": "streaming",
                "processing_time": time.time() - start_time,
                "chunks": len(response_chunks),
                "is_fast": False
            }
            
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì˜¤ë¥˜: {e}")
            return {
                "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "source": "error",
                "processing_time": time.time() - start_time,
                "is_fast": False
            }

    async def _generate_accurate_background(self, phone_id: str, user_text: str):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì •í™•í•œ ì‘ë‹µ ìƒì„±"""
        try:
            messages = [
                SystemMessage(content="ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."),
                HumanMessage(content=user_text)
            ]
            
            # ì •í™•í•œ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±
            response = await self.accurate_llm.ainvoke(messages)
            
            if response and response.content:
                # ì •í™•í•œ ì‘ë‹µìœ¼ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸
                exact_cache_key = f"llm_exact:{phone_id}:{hash(user_text)}"
                cache.set(exact_cache_key, response.content, timeout=self.cache_ttl)
                
                logger.info(f"ğŸ¯ ë°±ê·¸ë¼ìš´ë“œ ì •í™•í•œ ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response.content)}ì")
                
        except Exception as e:
            logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")

    def _cache_response(self, phone_id: str, user_text: str, response: str):
        """ì‘ë‹µ ìºì‹± (ë‹¤ì¤‘ ë ˆë²¨)"""
        try:
            # 1. ì™„ì „ ì¼ì¹˜ ìºì‹œ
            exact_cache_key = f"llm_exact:{phone_id}:{hash(user_text)}"
            cache.set(exact_cache_key, response, timeout=self.cache_ttl)
            
            # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ìºì‹œ
            keywords = self._extract_keywords(user_text.lower())
            keyword_cache_key = f"llm_keyword:{phone_id}:{hash(user_text) % 10}"
            
            cache.set(keyword_cache_key, {
                'text': user_text,
                'response': response,
                'keywords': keywords,
                'timestamp': time.time()
            }, timeout=self.cache_ttl)
            
            logger.info(f"ğŸ’¾ ì‘ë‹µ ìºì‹± ì™„ë£Œ: {len(response)}ì")
            
        except Exception as e:
            logger.warning(f"ìºì‹± ì‹¤íŒ¨: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
optimized_streaming_llm = OptimizedStreamingLLM()

# ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜
async def start_chat_optimized(phone_id: str, question: str) -> str:
    """ê¸°ì¡´ start_chat í•¨ìˆ˜ì˜ ìµœì í™”ëœ ë²„ì „"""
    try:
        result = await optimized_streaming_llm.get_instant_response(phone_id, question)
        return result.get('content', 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    except Exception as e:
        logger.error(f"ìµœì í™”ëœ ì±„íŒ… ì˜¤ë¥˜: {e}")
        return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}" 