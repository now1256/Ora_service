"""
LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ì›Œí¬í”Œë¡œìš° - ë‹¨ìˆœí™”ëœ ìµœì í™” ë²„ì „
LLM ì²˜ë¦¬ ì „ì²´ í”Œë¡œìš°ì™€ ì™¸ë¶€ í†µì‹  ê´€ë¦¬
"""
import logging
import sys
import os
import time
import concurrent.futures
from typing import Dict, Any
from django.conf import settings
from django.core.cache import cache

# ê³µí†µ HTTP í´ë¼ì´ì–¸íŠ¸ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../..'))
try:
    from shared.infrastructure.http_client import http_client
except ImportError:
    # ê³µí†µ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° requests ì§ì ‘ ì‚¬ìš©
    import requests
    http_client = None

from ..domain.services import llm_domain_service

logger = logging.getLogger(__name__)

class LLMWorkflowService:
    """LLM ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ - ë‹¨ìˆœí™”ëœ ìµœì í™”"""

    def __init__(self):
        self.domain_service = llm_domain_service
        self.tts_server_url = getattr(settings, 'TTS_SERVER_URL', 'http://tts_server:5002')

    def process_text_request(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ìš”ì²­ ì²˜ë¦¬ - ë‹¨ìˆœí™”ëœ ì›Œí¬í”Œë¡œìš°"""
        try:
            print("ğŸ”¥" * 20)
            print("ğŸ“¨ [LLM Workflow] STTì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì‹ !")
            print("ğŸ”¥" * 20)
            print(f"ğŸ“ í…ìŠ¤íŠ¸: {request_data.get('text', '')}")
            print(f"ğŸ“± ì „í™”ë²ˆí˜¸: {request_data.get('phoneId', 'N/A')}")
            print(f"ğŸ†” ì„¸ì…˜ ID: {request_data.get('sessionId', 'N/A')}")
            print(f"ğŸ”‘ ìš”ì²­ ID: {request_data.get('requestId', 'N/A')}")

            total_start_time = time.time()

            # 1. ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            validation_result = self.domain_service.validate_text_request(request_data)
            if not validation_result['valid']:
                return {
                    'success': False,
                    'error': validation_result['error'],
                    'stage': 'validation'
                }

            user_text = request_data.get('text', '')
      
            phone_id = request_data.get('phoneId', '')
      

            # 2. Weaviate ì €ì¥ë§Œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ (ìµœì í™” ìœ ì§€)
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                # 3. LLM ì²˜ë¦¬ (ë©”ì¸ ì‘ì—…)
                llm_start_time = time.time()
                llm_result = self.domain_service.process_text_with_llm(phone_id, user_text)
                llm_elapsed = time.time() - llm_start_time
                print(f"âš¡ LLM ì²˜ë¦¬ ì‹œê°„: {llm_elapsed:.4f}ì´ˆ")

                if not llm_result['success']:
                    return {
                        'success': False,
                        'error': llm_result['error'],
                        'stage': 'llm_processing'
                    }

                # 4. TTS ë©”ì‹œì§€ ìƒì„± (ë‹¨ìˆœí™”)
                tts_message = {
                    'phoneId': request_data.get('phoneId', ''),
                    'sessionId': request_data.get('sessionId', ''),
                    'requestId': request_data.get('requestId', ''),
                    'timestamp': request_data.get('timestamp', ''),
                    'voice_config': {'language': 'ko', 'speed': 1.0},
                    'text': llm_result['llm_response']
                }

                print(f"ğŸ¤– [LLM Workflow] LLM ì‘ë‹µ: '{llm_result['llm_response']}'")
                print(f"ğŸ“¦ [LLM Workflow] TTS ì„œë²„ë¡œ ì „ì†¡í•  ë©”ì‹œì§€: {tts_message}")

                # 5. TTS ì„œë²„ë¡œ ì „ì†¡
                send_result = self.send_to_tts_server(tts_message)


            total_elapsed = time.time() - total_start_time
            print(f"ğŸš€ [ìµœì í™”] ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_elapsed:.4f}ì´ˆ")

            return {
                'success': send_result['success'],
                'llm_response': llm_result['llm_response'],
                'processing_time': llm_result['processing_time'],
                'tts_response': send_result,
                'total_time': total_elapsed,
                'stage': 'completed'
            }

        except Exception as e:
            logger.error(f"âŒ [LLM Workflow] ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e),
                'stage': 'workflow_error'
            }

    def _save_to_weaviate_async(self, request_data: Dict[str, Any]) -> bool:
        """Weaviate ì €ì¥ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (ìœ ì¼í•œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
        try:
            self.domain_service.save_to_weaviate(request_data)
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ [ë¹„ë™ê¸°] Weaviate ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def send_to_tts_server(self, tts_message: Dict[str, Any]) -> Dict[str, Any]:
        """TTS ì„œë²„ë¡œ HTTP POST ì „ì†¡"""
        try:
            tts_url = f"{self.tts_server_url}/api/convert-tts/"
            print(f"ğŸ“¤ [LLM Workflow] TTS ì„œë²„ë¡œ HTTP ì „ì†¡: {tts_url}")

            if http_client:
                response = http_client.post(tts_url, tts_message)
                return response
            else:
                import requests
                response = requests.post(tts_url, json=tts_message, timeout=30, verify=False)

                if response.status_code == 200:
                    print("âœ… [LLM Workflow] TTS ì„œë²„ë¡œ ì „ì†¡ ì„±ê³µ!")
                    return {
                        'success': True,
                        'status_code': response.status_code,
                        'data': response.json() if response.content else None
                    }
                else:
                    print(f"âŒ [LLM Workflow] TTS ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                    return {
                        'success': False,
                        'status_code': response.status_code,
                        'error': response.text
                    }

        except Exception as e:
            logger.error(f"âŒ [LLM Workflow] TTS ì„œë²„ ì „ì†¡ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e)
            }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
llm_workflow_service = LLMWorkflowService()
