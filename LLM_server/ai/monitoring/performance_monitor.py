"""
ğŸš€ Advanced Performance Monitoring System
ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§, ìë™ ìµœì í™”, ë³‘ëª©ì  íƒì§€
"""
import asyncio
import time
import json
import logging
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
from enum import Enum
import psutil
import statistics

logger = logging.getLogger(__name__)

class MetricType(Enum):
    RESPONSE_TIME = "response_time"
    CACHE_HIT_RATE = "cache_hit_rate"
    ERROR_RATE = "error_rate"
    THROUGHPUT = "throughput"
    MODEL_PERFORMANCE = "model_performance"
    SYSTEM_RESOURCE = "system_resource"

@dataclass
class PerformanceMetric:
    timestamp: float
    metric_type: MetricType
    value: float
    metadata: Dict[str, Any]
    source: str

@dataclass  
class SystemSnapshot:
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_available_mb: float
    response_time_avg: float
    cache_hit_rate: float
    error_rate: float
    throughput_per_minute: float
    active_models: int

class PerformanceCollector:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.metrics = defaultdict(lambda: deque(maxlen=max_history))
        self.request_history = deque(maxlen=max_history)
        self.error_history = deque(maxlen=max_history)
        self.cache_stats = deque(maxlen=100)
        self.lock = threading.RLock()
        
        # ì‹¤ì‹œê°„ í†µê³„
        self.current_minute_requests = 0
        self.current_minute_errors = 0
        self.last_minute_reset = time.time()
    
    def record_request(self, source: str, processing_time: float, 
                      success: bool, cache_hit: bool = False,
                      model_used: str = None, **metadata) -> None:
        """ìš”ì²­ ê¸°ë¡"""
        timestamp = time.time()
        
        with self.lock:
            # ìš”ì²­ íˆìŠ¤í† ë¦¬
            self.request_history.append({
                'timestamp': timestamp,
                'source': source,
                'processing_time': processing_time,
                'success': success,
                'cache_hit': cache_hit,
                'model_used': model_used,
                'metadata': metadata
            })
            
            # ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ì¹´ìš´íŠ¸
            self._update_minute_stats()
            self.current_minute_requests += 1
            
            if not success:
                self.current_minute_errors += 1
                self.error_history.append({
                    'timestamp': timestamp,
                    'source': source,
                    'error': metadata.get('error', 'Unknown error')
                })
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            self.metrics[MetricType.RESPONSE_TIME].append(
                PerformanceMetric(
                    timestamp=timestamp,
                    metric_type=MetricType.RESPONSE_TIME,
                    value=processing_time,
                    metadata={'source': source, 'model': model_used},
                    source=source
                )
            )
    
    def record_cache_stats(self, cache_stats: Dict[str, Any]) -> None:
        """ìºì‹œ í†µê³„ ê¸°ë¡"""
        timestamp = time.time()
        
        with self.lock:
            self.cache_stats.append({
                'timestamp': timestamp,
                **cache_stats
            })
            
            # ìºì‹œ íˆíŠ¸ìœ¨ ë©”íŠ¸ë¦­
            hit_rate = cache_stats.get('total_hit_rate', 0)
            self.metrics[MetricType.CACHE_HIT_RATE].append(
                PerformanceMetric(
                    timestamp=timestamp,
                    metric_type=MetricType.CACHE_HIT_RATE,
                    value=hit_rate,
                    metadata=cache_stats,
                    source='cache_system'
                )
            )
    
    def _update_minute_stats(self) -> None:
        """ë¶„ë‹¨ìœ„ í†µê³„ ì—…ë°ì´íŠ¸"""
        current_time = time.time()
        if current_time - self.last_minute_reset >= 60:
            self.current_minute_requests = 0
            self.current_minute_errors = 0
            self.last_minute_reset = current_time
    
    def get_recent_metrics(self, metric_type: MetricType, 
                          duration_seconds: int = 300) -> List[PerformanceMetric]:
        """ìµœê·¼ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        cutoff_time = time.time() - duration_seconds
        
        with self.lock:
            return [
                metric for metric in self.metrics[metric_type]
                if metric.timestamp >= cutoff_time
            ]
    
    def get_system_snapshot(self) -> SystemSnapshot:
        """í˜„ì¬ ì‹œìŠ¤í…œ ìŠ¤ëƒ…ìƒ·"""
        with self.lock:
            # ìµœê·¼ 5ë¶„ ìš”ì²­ë“¤
            recent_requests = [
                req for req in self.request_history
                if time.time() - req['timestamp'] <= 300
            ]
            
            # ì‘ë‹µ ì‹œê°„ í‰ê· 
            successful_requests = [req for req in recent_requests if req['success']]
            avg_response_time = statistics.mean([
                req['processing_time'] for req in successful_requests
            ]) if successful_requests else 0.0
            
            # ìºì‹œ íˆíŠ¸ìœ¨
            cache_hits = sum(1 for req in recent_requests if req.get('cache_hit'))
            cache_hit_rate = (cache_hits / len(recent_requests) * 100) if recent_requests else 0.0
            
            # ì—ëŸ¬ìœ¨
            error_count = len([req for req in recent_requests if not req['success']])
            error_rate = (error_count / len(recent_requests) * 100) if recent_requests else 0.0
            
            # ë¶„ë‹¹ ì²˜ë¦¬ëŸ‰
            throughput = len(recent_requests) / 5.0  # 5ë¶„ í‰ê· 
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
            memory = psutil.virtual_memory()
            
            return SystemSnapshot(
                timestamp=time.time(),
                cpu_percent=psutil.cpu_percent(),
                memory_percent=memory.percent,
                memory_available_mb=memory.available / 1024 / 1024,
                response_time_avg=avg_response_time,
                cache_hit_rate=cache_hit_rate,
                error_rate=error_rate,
                throughput_per_minute=throughput * 12,  # ë¶„ë‹¹ ë³€í™˜
                active_models=len(set(req.get('model_used') for req in recent_requests if req.get('model_used')))
            )

class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.alert_rules = {
            'high_response_time': {'threshold': 2.0, 'enabled': True},
            'low_cache_hit_rate': {'threshold': 50.0, 'enabled': True},
            'high_error_rate': {'threshold': 10.0, 'enabled': True},
            'high_memory_usage': {'threshold': 80.0, 'enabled': True},
            'high_cpu_usage': {'threshold': 90.0, 'enabled': True}
        }
        self.alert_history = deque(maxlen=100)
        self.last_alerts = {}  # ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€
    
    def check_alerts(self, snapshot: SystemSnapshot) -> List[Dict[str, Any]]:
        """ì•Œë¦¼ ì¡°ê±´ ì²´í¬"""
        alerts = []
        current_time = time.time()
        
        # ì‘ë‹µ ì‹œê°„ ì•Œë¦¼
        if (self.alert_rules['high_response_time']['enabled'] and 
            snapshot.response_time_avg > self.alert_rules['high_response_time']['threshold']):
            alert = self._create_alert(
                'high_response_time',
                f"í‰ê·  ì‘ë‹µ ì‹œê°„ì´ {snapshot.response_time_avg:.2f}ì´ˆë¡œ ë†’ìŠµë‹ˆë‹¤",
                'warning',
                {'response_time': snapshot.response_time_avg}
            )
            alerts.append(alert)
        
        # ìºì‹œ íˆíŠ¸ìœ¨ ì•Œë¦¼
        if (self.alert_rules['low_cache_hit_rate']['enabled'] and 
            snapshot.cache_hit_rate < self.alert_rules['low_cache_hit_rate']['threshold']):
            alert = self._create_alert(
                'low_cache_hit_rate',
                f"ìºì‹œ íˆíŠ¸ìœ¨ì´ {snapshot.cache_hit_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤",
                'warning',
                {'cache_hit_rate': snapshot.cache_hit_rate}
            )
            alerts.append(alert)
        
        # ì—ëŸ¬ìœ¨ ì•Œë¦¼
        if (self.alert_rules['high_error_rate']['enabled'] and 
            snapshot.error_rate > self.alert_rules['high_error_rate']['threshold']):
            alert = self._create_alert(
                'high_error_rate',
                f"ì—ëŸ¬ìœ¨ì´ {snapshot.error_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤",
                'critical',
                {'error_rate': snapshot.error_rate}
            )
            alerts.append(alert)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•Œë¦¼
        if (self.alert_rules['high_memory_usage']['enabled'] and 
            snapshot.memory_percent > self.alert_rules['high_memory_usage']['threshold']):
            alert = self._create_alert(
                'high_memory_usage',
                f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ {snapshot.memory_percent:.1f}%ì…ë‹ˆë‹¤",
                'warning',
                {'memory_percent': snapshot.memory_percent}
            )
            alerts.append(alert)
        
        # CPU ì‚¬ìš©ëŸ‰ ì•Œë¦¼
        if (self.alert_rules['high_cpu_usage']['enabled'] and 
            snapshot.cpu_percent > self.alert_rules['high_cpu_usage']['threshold']):
            alert = self._create_alert(
                'high_cpu_usage',
                f"CPU ì‚¬ìš©ëŸ‰ì´ {snapshot.cpu_percent:.1f}%ì…ë‹ˆë‹¤",
                'critical',
                {'cpu_percent': snapshot.cpu_percent}
            )
            alerts.append(alert)
        
        # ì¤‘ë³µ ì•Œë¦¼ í•„í„°ë§ ë° ê¸°ë¡
        filtered_alerts = []
        for alert in alerts:
            alert_key = f"{alert['type']}_{alert['severity']}"
            last_alert_time = self.last_alerts.get(alert_key, 0)
            
            # 5ë¶„ ì´ë‚´ ë™ì¼ ì•Œë¦¼ì€ ìŠ¤í‚µ
            if current_time - last_alert_time > 300:
                filtered_alerts.append(alert)
                self.last_alerts[alert_key] = current_time
                self.alert_history.append(alert)
        
        return filtered_alerts
    
    def _create_alert(self, alert_type: str, message: str, severity: str, 
                     metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ì•Œë¦¼ ìƒì„±"""
        return {
            'timestamp': time.time(),
            'type': alert_type,
            'message': message,
            'severity': severity,
            'metadata': metadata
        }

class AutoOptimizer:
    """ìë™ ìµœì í™” ì—”ì§„"""
    
    def __init__(self):
        self.optimization_history = deque(maxlen=50)
        self.last_optimization = 0
        self.optimization_cooldown = 300  # 5ë¶„
    
    def suggest_optimizations(self, snapshot: SystemSnapshot, 
                            recent_metrics: Dict[MetricType, List[PerformanceMetric]]) -> List[Dict[str, Any]]:
        """ìµœì í™” ì œì•ˆ"""
        suggestions = []
        current_time = time.time()
        
        # ì¿¨ë‹¤ìš´ ì²´í¬
        if current_time - self.last_optimization < self.optimization_cooldown:
            return suggestions
        
        # ì‘ë‹µ ì‹œê°„ ìµœì í™”
        if snapshot.response_time_avg > 1.0:
            if snapshot.cache_hit_rate < 70.0:
                suggestions.append({
                    'type': 'cache_optimization',
                    'priority': 'high',
                    'description': 'ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ìºì‹œ TTLì„ ëŠ˜ë¦¬ê±°ë‚˜ ë” ë§ì€ íŒ¨í„´ì„ ìºì‹±í•˜ì„¸ìš”.',
                    'recommended_actions': [
                        'increase_cache_ttl',
                        'expand_pattern_cache',
                        'enable_predictive_cache'
                    ]
                })
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì œì•ˆ
            suggestions.append({
                'type': 'parallel_optimization', 
                'priority': 'medium',
                'description': 'ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤. ë” ë§ì€ LLMì„ ë³‘ë ¬ë¡œ í˜¸ì¶œí•˜ê±°ë‚˜ ë¡œì»¬ LLMì„ ì¶”ê°€í•˜ì„¸ìš”.',
                'recommended_actions': [
                    'enable_more_parallel_models',
                    'reduce_model_timeout',
                    'use_faster_models'
                ]
            })
        
        # ë¦¬ì†ŒìŠ¤ ìµœì í™”
        if snapshot.memory_percent > 70.0:
            suggestions.append({
                'type': 'memory_optimization',
                'priority': 'medium',
                'description': 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ìºì‹œ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.',
                'recommended_actions': [
                    'reduce_cache_size',
                    'cleanup_old_metrics',
                    'optimize_model_loading'
                ]
            })
        
        # ëª¨ë¸ ì„ íƒ ìµœì í™”
        response_time_metrics = recent_metrics.get(MetricType.RESPONSE_TIME, [])
        if response_time_metrics:
            model_performance = defaultdict(list)
            for metric in response_time_metrics:
                model = metric.metadata.get('model')
                if model:
                    model_performance[model].append(metric.value)
            
            # ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ì¶”ì²œ
            if len(model_performance) > 1:
                avg_times = {
                    model: statistics.mean(times) 
                    for model, times in model_performance.items()
                }
                fastest_model = min(avg_times, key=avg_times.get)
                slowest_model = max(avg_times, key=avg_times.get)
                
                if avg_times[slowest_model] > avg_times[fastest_model] * 2:
                    suggestions.append({
                        'type': 'model_optimization',
                        'priority': 'medium',
                        'description': f'{fastest_model}ì´ {slowest_model}ë³´ë‹¤ 2ë°° ë¹ ë¦…ë‹ˆë‹¤.',
                        'recommended_actions': [
                            f'prioritize_{fastest_model}',
                            f'reduce_{slowest_model}_usage'
                        ]
                    })
        
        if suggestions:
            self.last_optimization = current_time
            for suggestion in suggestions:
                self.optimization_history.append({
                    'timestamp': current_time,
                    **suggestion
                })
        
        return suggestions

class PerformanceMonitor:
    """í†µí•© ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.collector = PerformanceCollector()
        self.alert_manager = AlertManager()
        self.optimizer = AutoOptimizer()
        self.monitoring_active = False
        self.monitoring_task = None
        self.dashboard_data = {}
        
        # ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)
        self.monitoring_interval = 30
    
    async def start_monitoring(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        logger.info("ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    async def stop_monitoring(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitoring_task:
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
        logger.info("â¹ï¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    async def _monitoring_loop(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            try:
                # ì‹œìŠ¤í…œ ìŠ¤ëƒ…ìƒ· ìƒì„±
                snapshot = self.collector.get_system_snapshot()
                
                # ìµœê·¼ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                recent_metrics = {}
                for metric_type in MetricType:
                    recent_metrics[metric_type] = self.collector.get_recent_metrics(metric_type, 300)
                
                # ì•Œë¦¼ ì²´í¬
                alerts = self.alert_manager.check_alerts(snapshot)
                for alert in alerts:
                    logger.warning(f"ğŸš¨ ì•Œë¦¼: {alert['message']}")
                
                # ìµœì í™” ì œì•ˆ
                suggestions = self.optimizer.suggest_optimizations(snapshot, recent_metrics)
                for suggestion in suggestions:
                    logger.info(f"ğŸ’¡ ìµœì í™” ì œì•ˆ: {suggestion['description']}")
                
                # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì—…ë°ì´íŠ¸
                self.dashboard_data = {
                    'snapshot': asdict(snapshot),
                    'alerts': alerts,
                    'suggestions': suggestions,
                    'last_updated': time.time()
                }
                
                await asyncio.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(5)
    
    def record_request(self, **kwargs) -> None:
        """ìš”ì²­ ê¸°ë¡ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤)"""
        self.collector.record_request(**kwargs)
    
    def record_cache_stats(self, cache_stats: Dict[str, Any]) -> None:
        """ìºì‹œ í†µê³„ ê¸°ë¡ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤)"""
        self.collector.record_cache_stats(cache_stats)
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ"""
        return self.dashboard_data
    
    def get_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        duration_seconds = hours * 3600
        current_time = time.time()
        
        # ê° ë©”íŠ¸ë¦­ íƒ€ì…ë³„ í†µê³„
        report = {
            'report_period_hours': hours,
            'generated_at': current_time,
            'metrics': {}
        }
        
        for metric_type in MetricType:
            metrics = self.collector.get_recent_metrics(metric_type, duration_seconds)
            if metrics:
                values = [m.value for m in metrics]
                report['metrics'][metric_type.value] = {
                    'count': len(values),
                    'average': statistics.mean(values),
                    'median': statistics.median(values),
                    'min': min(values),
                    'max': max(values),
                    'std_dev': statistics.stdev(values) if len(values) > 1 else 0
                }
        
        # ìµœê·¼ ì•Œë¦¼
        recent_alerts = [
            alert for alert in self.alert_manager.alert_history
            if current_time - alert['timestamp'] <= duration_seconds
        ]
        report['alerts_summary'] = {
            'total_alerts': len(recent_alerts),
            'by_severity': {
                'critical': len([a for a in recent_alerts if a['severity'] == 'critical']),
                'warning': len([a for a in recent_alerts if a['severity'] == 'warning']),
                'info': len([a for a in recent_alerts if a['severity'] == 'info'])
            }
        }
        
        # ìµœì í™” ì œì•ˆ ì´ë ¥
        recent_optimizations = [
            opt for opt in self.optimizer.optimization_history
            if current_time - opt['timestamp'] <= duration_seconds
        ]
        report['optimization_summary'] = {
            'total_suggestions': len(recent_optimizations),
            'by_type': {}
        }
        
        for opt in recent_optimizations:
            opt_type = opt['type']
            if opt_type not in report['optimization_summary']['by_type']:
                report['optimization_summary']['by_type'][opt_type] = 0
            report['optimization_summary']['by_type'][opt_type] += 1
        
        return report

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
performance_monitor = PerformanceMonitor()